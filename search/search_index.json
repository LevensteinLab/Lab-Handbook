{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Lab-Handbook The lab handbook of the Levenstein Lab for NeuroAI and Dynamics at Yale University. Please note that this is an in-development and \"living document\", which means that it will evolve as needed to fit the lab as it grows and develops. Furthermore, it means that as a lab member, you're encouraged to contribute and discuss its contents with Dan and in the #lab-handbook channel on slack. About the lab Like learning, sleep changes the brain to improve its future performance. Unlike learning, these changes occur in the absence of overt behavior or sensory input, and rely solely on neural activity that is spontaneously generated by the brain itself. This \u201coffline learning\u201d thus contains a mystery: how does spontaneous activity improve brain function? Our lab aims to develop theories of offline learning that shed light on this mystery, and can be used to mimic its computational benefits in artificial neural networks or understand its disruption in neuropsychiatric disorders. Our work generally focuses on spatial representation in the hippocampal formation, and a phenomenon called sharp wave ripples - high frequency oscillations in the hippocampus that coordinate activity across the brain and simulate wake-like \u201creplay\u201d trajectories during sleep. We use artificial neural networks (ANNs), dynamical systems theory, and neural data analysis to study how these internally-generated dynamics support offline learning \u2013 working closely with experimental collaborators to inspire the design of computational models and to compare them in experimental data. This NeuroAI approach, in which brain-inspired ANNs are built and used as models for the brain, is particularly well-suited to bridge neurons\u2019 circuit and cellular-level properties with their computational capacities, and allows us to study three questions central to our research: \u201c How does spontaneous activity emerge and self-organize in neural networks? \u201d \u201c How does plasticity during spontaneous activity change the brain? \u201d \u201c How do those changes improve the brain\u2019s operations and performance on future tasks? \u201d In addition to our work on sleep, the lab works broadly at the interface of theoretical and experimental neuroscience - applying computational methods to a variety of interesting problems involving neural dynamics and computation with experimentalist collaborators. Where to start? So you want to join the lab? - prospective members start here Onboarding - new members start here","title":"Lab-Handbook"},{"location":"#lab-handbook","text":"The lab handbook of the Levenstein Lab for NeuroAI and Dynamics at Yale University. Please note that this is an in-development and \"living document\", which means that it will evolve as needed to fit the lab as it grows and develops. Furthermore, it means that as a lab member, you're encouraged to contribute and discuss its contents with Dan and in the #lab-handbook channel on slack. About the lab Like learning, sleep changes the brain to improve its future performance. Unlike learning, these changes occur in the absence of overt behavior or sensory input, and rely solely on neural activity that is spontaneously generated by the brain itself. This \u201coffline learning\u201d thus contains a mystery: how does spontaneous activity improve brain function? Our lab aims to develop theories of offline learning that shed light on this mystery, and can be used to mimic its computational benefits in artificial neural networks or understand its disruption in neuropsychiatric disorders. Our work generally focuses on spatial representation in the hippocampal formation, and a phenomenon called sharp wave ripples - high frequency oscillations in the hippocampus that coordinate activity across the brain and simulate wake-like \u201creplay\u201d trajectories during sleep. We use artificial neural networks (ANNs), dynamical systems theory, and neural data analysis to study how these internally-generated dynamics support offline learning \u2013 working closely with experimental collaborators to inspire the design of computational models and to compare them in experimental data. This NeuroAI approach, in which brain-inspired ANNs are built and used as models for the brain, is particularly well-suited to bridge neurons\u2019 circuit and cellular-level properties with their computational capacities, and allows us to study three questions central to our research: \u201c How does spontaneous activity emerge and self-organize in neural networks? \u201d \u201c How does plasticity during spontaneous activity change the brain? \u201d \u201c How do those changes improve the brain\u2019s operations and performance on future tasks? \u201d In addition to our work on sleep, the lab works broadly at the interface of theoretical and experimental neuroscience - applying computational methods to a variety of interesting problems involving neural dynamics and computation with experimentalist collaborators. Where to start? So you want to join the lab? - prospective members start here Onboarding - new members start here","title":"Lab-Handbook"},{"location":"contact/","text":"Lab Information Wu Tsai Institute, Center for Neurocomputation and Machine Intelligence 100 College Street, New Haven, CT 06511 Lab Members Name Role Email Daniel Levenstein Primary Investigator daniel.levenstein@yale.edu Andrea Cumpelik Postdoctoral Researcher andrea.cumpelik@yale.edu Viggy Vanchinathan Postgraduate Associate vignesh.vanchinathan@yale.edu Huihong Li Masters Student huihong.li@yale.edu Aidan Schneider Postdoctoral Researcher aidan.schneider@yale.edu","title":"Contact"},{"location":"onboarding/","text":"This page delineates the onboarding processes. Please try to follow it step by step. If/when you find steps that are out of date, that are poorly described, or that you think should be added to the process, please update the Lab Handbook. You should have made at least one change by the time you complete onboarding (if you don\u2019t know how to do that, you\u2019ll learn!), and please follow this practice whenever using the lab handbook. Important Emails to Look For Appointment Confirmation, from AutomationManager@brassring.com Outlines position, job responsibilities, compensation, funding sources, term length. Welcome E-mail, from Jennifer Coughlin Access to NetID, your Yale email, and Workday for trainings/benefits New to Yale? Get Yale NetID/email (note: this will take about 24 hours) Your NetID is a unique identifier for you in the system, and can also be used to log into the private YaleSecure WiFi network. Emails typically follow first.last@yale.edu ; you may need to wait for 20 minutes or more after your netID activation to access your email. Set up multifactor authentication (MFA) Usually done through Duo, which you will need to access your email. Find additional information on how to set this up here . If you'd like to change your 2FA device(s), you can navigate directly to mfa.its.yale.edu and sign in. Get Yale ID card Multiple offices are available to get an ID card printed. Note the hours! Yale Central ID Center, 57 Lock St ( M-F, 8am-4pm ), walk-in visits accepted but appointments are encouraged. Medical School ID Center, 333 Cedar St ( M-Th, 8am-12pm ) for walk-ins Get 100 College/WTI card access (note: it will take about 24 hours for your card to gain access) Note that a Yale ID card does NOT automatically provide access to 100 College/WTI. You must request access seaparately; ideally email the WTI facilities manager, Matt Milano . Familiarize yourself with campus, and how to get to 100 College Institute Multiple areas of campus (Old Campus, Science Hill, etc) The Wu Tsai Institute is located on the 11th floor at 100 College Street. The building is owned by Alexion Pharmaceuticals (owned by AstraZeneca) We are located in the Center for Neurocomputation and Machine Intelligence, to the right side if you are facing towards the \"Yale Wu Tsai Institute\" sign. Sign up for an orientation. These are available for both Postdocs and Postgrads. Workday stuff Complete your I-9 . It is a federal requirement that the I-9 form is submitted by three business days of your start date. Bring the right documents ! The main office where you can get an appointment is 221 Whitney Avenue Sign up for Health insurance and please see the lab handbook section on health, wellness, and work-life balance Complete the required training courses with Workday Learning Trainings may take multiple hours, and you may want to do this over multiple days. Your first day Join the lab slack . You'll be added to some channels, but take a look through the channels and join any that interest you! Fill out this form to get access to the Wu Tsai Institute slack. Familiarize yourself with Lab policies, practices, and expectations. You don\u2019t need to read the whole thing, but do read over the expectations for your position in the lab and working hours, remote working, and vacation Send Viggy a preferred email for the shared lab Google Calendar. You'll receive read & write access to see & add events. We also have an slack integration set up to send reminders for upcoming events. Schedule your regular 1-on-1 meeting with Dan. Send Dan your headshot and bio for the lab website. Join Levenstein Lab github organization - send Dan your github username and he'll add you Basic Github tutorial - make your github account, learn to make a PR. Follow the lab handbook repository so you get notified of future updates to the handbook, and have the opportunity to read and discuss them Your first PR: Update the lab handbook to improve something that was unclear or missing up until now. Add your contact information to contact.md Join Mailing lists/groups at Yale First readings (first week) : Discuss with Dan your interests and potential first projects. In addition to any reading he suggests, take a look at Recommended Reading . If you\u2019re new to working with neural networks, or to neuroAI, I highly recommend these as places to start: Artificial Neural Networks for Neuroscientists: A Primer A deep learning framework for neuroscience The neuroconnectionist research programme Getting started (1-2 Weeks) : Read about the Lab Code and Software Practices , and the introduction of the good research code handbook . We don\u2019t follow this religiously, but it\u2019s a good place to start. Something to remember: the main outputs of your work in the lab will be ideas , figures , and code . Of those, your code is unique - it's your primary research tool and its the best way for other people (including your future self) to be able reproduce and build on your work. Thus, it behooves you to invest some energy in writing good code. If you don't have a preferred IDE, Get VS Code and do the VS code tutorial Follow either the ANN path or the data analysis path below ANNs path Your first project: Complete the Learn the Basics PyTorch Tutorial. First set up a project repository in which you'll do the tutorial - THIS IS THE MOST IMPORTANT STEP. Setting up a project repository, with its own environment and specified dependencies, will save you infinite headaches in the future. Get in the practice now. By the end of this tutorial, you should have trained a multi-layer perceptron (MLP) to solve fMNIST. Next, modify the network in some way you find interesting. Get set up on the misha compute cluster and learn how to use it . Your second project: pRNN Tutorials By the end of this, you should have trained a basic predictive RNN in a gridworld environment, and analyzed its spatial tuning properties Next, modify or use the pRNN network in some way you find interesting. This could involve a new environment or behavioral policy, or changes to the network architecture, loss, or learning rule. Feel free to discuss some ideas with Dan. Data analysis path : Your first project: discuss with Dan the data you'd like to work with and choose your own adventure ;)... this path is still under construction. Consider working with pynapple , which is a good package for working with neural timeseries data and has some tutorials.","title":"Onboarding"},{"location":"Policies/code_software/","text":"Code and software practices Maintaining good code is essential to the efficient functioning of the lab. Best software practices mandate that the code is well-documented, commented, and modular. As code may be shared within our lab (and outside), these guidlines ensure that the code is understandable and usable quickly. There are plenty of great resources online regarding how to follow these practices. Good Research Code Handbook Here's how we may format our code as a lab: Repository Types Project (\u201cLab Notebook\u201d): A repository for managing the day-to-day progress of a research project \u2014 analyses in progress, exploratory modeling, notes, and experiment logs. The cookie cutter repository (as described in the good research code handbook) is a good place to start, which will get you started with a file structure and environment. Each project should have its own repository. Package : In the course of a project, you\u2019ll likely develop something reusable \u2014 e.g., a model, simulation tool, or analysis pipeline. A package is a cleaned-up, documented, and versioned version of that tool, designed so others (future lab members and the broader community) can easily use and extend it. This repository should be jointly owned by you and the lab organization (e.g., under the lab\u2019s GitHub org). As your project moves from an exploration to an exploitation phase, work with Viggy to create and maintain a package repository. Publication : A repository for reproducing all figures and analyses in a specific paper. This repository is owned by the lab organization (since publications represent lab outputs). As you prepare to submit a manuscript, work with Viggy to set up this repository. The paper repository should depend on the relevant package (don\u2019t reimplement analysis code) and should pin specific package versions (e.g., via requirements.txt, pyproject.toml, or git submodules) to ensure reproducibility. Include figure-generation scripts, processed data, and notebooks. Conventions Patrick Mineault's code handbook above is a must-read before you start coding. It reviews the best ways to set up your project, to maintain clarity and cleanliness, to test your code, and to document your code as well. The handbook is the best way to learn these conventions, especially when it comes to efficiency and testing, which rely on great examples. However a few helpful tips to get you started in the right direction Use git often, often more than you think you should. See Resources and How-Tos/basic_github.md for additional information. Setup your repository correctly, from the beginning. Mineault's base directory structure works really well to keep the inputs and outputs of your code separate: data folder: raw input data docs folder: documentation, kept separate for later publishing results folder: code outputs, figures, tables, CSVs scripts folder: scripts for analysis like .ipynb notebooks srcs folder: reusable code that works at the base of all the scripts tests folder: unit tests This can be downloaded with the true-neutral-cookiecutter . Maintain your environments. Packages you import may have dependences on other packages with specific versions, or perhaps even specific versions of python. Installing all packages into one environment will make it extremely difficult to move the code to another computer or user (i.e. it's less portable ). We can use conda as a package manager and virtual environment manager for this. conda can be installed via miniconda , which is a lighter-weight version of the original Anaconda Distribution of packages/python. This will allow you to use conda to make virtual environments and manage packages. Use a .yml file. These are special files that specify instructions on which packages comprise an environment. A different researcher using your code can automatically recreate your environment exactly as you have it by using this file, ensuring proper portability. Maintain good style. This includes commenting, which should be done at the top of functions, classes, modules, files, etc. This helps both you and others understand code. Pythonic code can be confusing sometimes; you'll need to make the tradeoff between clarity and brevity. Download a linter (e.g. Ruff) to help you format your code. VS Code VS Code is a great IDE because it's open source (unlike e.g. PyCharm), highly customizable via extensions, and has great remote development support (which is important when working with the cluster). You can download it here . If you are unfamiliar with VS Code/IDEs in general, see the VS Code tutorial for more info on how to get started.","title":"Good Software"},{"location":"Policies/code_software/#code-and-software-practices","text":"Maintaining good code is essential to the efficient functioning of the lab. Best software practices mandate that the code is well-documented, commented, and modular. As code may be shared within our lab (and outside), these guidlines ensure that the code is understandable and usable quickly. There are plenty of great resources online regarding how to follow these practices. Good Research Code Handbook Here's how we may format our code as a lab:","title":"Code and software practices"},{"location":"Policies/code_software/#repository-types","text":"Project (\u201cLab Notebook\u201d): A repository for managing the day-to-day progress of a research project \u2014 analyses in progress, exploratory modeling, notes, and experiment logs. The cookie cutter repository (as described in the good research code handbook) is a good place to start, which will get you started with a file structure and environment. Each project should have its own repository. Package : In the course of a project, you\u2019ll likely develop something reusable \u2014 e.g., a model, simulation tool, or analysis pipeline. A package is a cleaned-up, documented, and versioned version of that tool, designed so others (future lab members and the broader community) can easily use and extend it. This repository should be jointly owned by you and the lab organization (e.g., under the lab\u2019s GitHub org). As your project moves from an exploration to an exploitation phase, work with Viggy to create and maintain a package repository. Publication : A repository for reproducing all figures and analyses in a specific paper. This repository is owned by the lab organization (since publications represent lab outputs). As you prepare to submit a manuscript, work with Viggy to set up this repository. The paper repository should depend on the relevant package (don\u2019t reimplement analysis code) and should pin specific package versions (e.g., via requirements.txt, pyproject.toml, or git submodules) to ensure reproducibility. Include figure-generation scripts, processed data, and notebooks.","title":"Repository Types"},{"location":"Policies/code_software/#conventions","text":"Patrick Mineault's code handbook above is a must-read before you start coding. It reviews the best ways to set up your project, to maintain clarity and cleanliness, to test your code, and to document your code as well. The handbook is the best way to learn these conventions, especially when it comes to efficiency and testing, which rely on great examples. However a few helpful tips to get you started in the right direction Use git often, often more than you think you should. See Resources and How-Tos/basic_github.md for additional information. Setup your repository correctly, from the beginning. Mineault's base directory structure works really well to keep the inputs and outputs of your code separate: data folder: raw input data docs folder: documentation, kept separate for later publishing results folder: code outputs, figures, tables, CSVs scripts folder: scripts for analysis like .ipynb notebooks srcs folder: reusable code that works at the base of all the scripts tests folder: unit tests This can be downloaded with the true-neutral-cookiecutter . Maintain your environments. Packages you import may have dependences on other packages with specific versions, or perhaps even specific versions of python. Installing all packages into one environment will make it extremely difficult to move the code to another computer or user (i.e. it's less portable ). We can use conda as a package manager and virtual environment manager for this. conda can be installed via miniconda , which is a lighter-weight version of the original Anaconda Distribution of packages/python. This will allow you to use conda to make virtual environments and manage packages. Use a .yml file. These are special files that specify instructions on which packages comprise an environment. A different researcher using your code can automatically recreate your environment exactly as you have it by using this file, ensuring proper portability. Maintain good style. This includes commenting, which should be done at the top of functions, classes, modules, files, etc. This helps both you and others understand code. Pythonic code can be confusing sometimes; you'll need to make the tradeoff between clarity and brevity. Download a linter (e.g. Ruff) to help you format your code.","title":"Conventions"},{"location":"Policies/code_software/#vs-code","text":"VS Code is a great IDE because it's open source (unlike e.g. PyCharm), highly customizable via extensions, and has great remote development support (which is important when working with the cluster). You can download it here . If you are unfamiliar with VS Code/IDEs in general, see the VS Code tutorial for more info on how to get started.","title":"VS Code"},{"location":"Policies/conferences_workshops/","text":"Conferences You are encouraged to submit your work to conferences. If you are presenting your work, the lab will fund your registration and travel and any other conference-related expenses. Meals can be reimbursed via saving all your receipts, or through a per diem (I\u2019d recommend the per diem). Please try to keep these costs down (e.g. with flight and hotel selection, and booking early). Please also keep your eyes out and apply for any travel awards. Your CV and the lab\u2019s wallet will thank you. Like with other fellowship opportunities, I'll also forward travel award opportunities to the lab when I see them. Please plan to send me a draft of your abstract one week before deadline . This gives us enough time for a few rounds of edits and discussion, and to develop the story together. Your work, and your abstract acceptance rate, will thank you. I\u2019ll note that you often feel like your project is not-quite-ready when you start writing your abstract, and that the abstract writing process is often when the project gets developed to the point where it\u2019s ready to submit\u2026 long story short, don\u2019t be afraid to write an abstract even if you feel you\u2019re not ready :) As with a paper submission, nothing goes out without all co-authors seeing and approving the final version. The exact number of conferences you should expect to present at per year will depend on your career stage, and status of your project. IMO the best times to present are when you're halfway through a project, and trying to figure out what the story is, and just after you've posted a preprint. See Resources - Travel for information on booking travel.","title":"Conferences and Workshops"},{"location":"Policies/conferences_workshops/#conferences","text":"You are encouraged to submit your work to conferences. If you are presenting your work, the lab will fund your registration and travel and any other conference-related expenses. Meals can be reimbursed via saving all your receipts, or through a per diem (I\u2019d recommend the per diem). Please try to keep these costs down (e.g. with flight and hotel selection, and booking early). Please also keep your eyes out and apply for any travel awards. Your CV and the lab\u2019s wallet will thank you. Like with other fellowship opportunities, I'll also forward travel award opportunities to the lab when I see them. Please plan to send me a draft of your abstract one week before deadline . This gives us enough time for a few rounds of edits and discussion, and to develop the story together. Your work, and your abstract acceptance rate, will thank you. I\u2019ll note that you often feel like your project is not-quite-ready when you start writing your abstract, and that the abstract writing process is often when the project gets developed to the point where it\u2019s ready to submit\u2026 long story short, don\u2019t be afraid to write an abstract even if you feel you\u2019re not ready :) As with a paper submission, nothing goes out without all co-authors seeing and approving the final version. The exact number of conferences you should expect to present at per year will depend on your career stage, and status of your project. IMO the best times to present are when you're halfway through a project, and trying to figure out what the story is, and just after you've posted a preprint. See Resources - Travel for information on booking travel.","title":"Conferences"},{"location":"Policies/health_wellness/","text":"Health, wellness, and work-life balance More to come. See also mental health resources","title":"Health & Wellness"},{"location":"Policies/health_wellness/#health-wellness-and-work-life-balance","text":"More to come. See also mental health resources","title":"Health, wellness, and work-life balance"},{"location":"Policies/hours_remote_vacation/","text":"Working hours, remote work, and vacation As our work is predominantly theoretical/computational, we have a lot of flexibility around when and where we work. Please set your hours based on how you work best. That being said, part of our job is being a contributing member to the lab community, and in my experience the spontaneous interactions we have here are some of the most impactful for the quality of our research. I'm generally in lab ~930-~6, and I try to be as available as possible during that time. If it fits you, I would encourage you to plan one day a week where you work from home (or elsewhere out of office). This shift in perspective can be helpful for your work and I encourage you to take advantage of this time to think freely and critically about your project and current approaches. I do ask that you plan to attend lab meetings in person -- in my experience, remote attendance encourages people to listen (at best), rather than participate, in lab meetings. Also, I ask that you plan to be physically in lab 3-4 days a week. Of course, this can vary week to week and exceptions will be made to fit people\u2019s circumstances. I will sometimes message at evenings, or on weekends. Please do not think this means I expect you to act on, or even read, the message until the next workday unless it\u2019s specifically designated as urgent/time sensitive. It only means that I thought of something relevant to your project and didn\u2019t want to forget. If you'd prefer I not message you outside of working hours (unless urgent), please let me know and I'll schedule these for the next workday. I expect you will be taking vacations. I usually take off from the weekend before Christmas until the weekend after new years, a few days around thanksgiving, a week or two over the summer, and the various official 3-day weekends. I\u2019ll lightly respond to emails during these times, do some reading, maybe some writing. But in general I like to use this time to recharge, spend some time with family and hobbies, and I encourage you all to do the same. For more about work-life balance in academia, please see [Work-life balance] TODO: @dan include link .","title":"Hours & Remote Work"},{"location":"Policies/hours_remote_vacation/#working-hours-remote-work-and-vacation","text":"As our work is predominantly theoretical/computational, we have a lot of flexibility around when and where we work. Please set your hours based on how you work best. That being said, part of our job is being a contributing member to the lab community, and in my experience the spontaneous interactions we have here are some of the most impactful for the quality of our research. I'm generally in lab ~930-~6, and I try to be as available as possible during that time. If it fits you, I would encourage you to plan one day a week where you work from home (or elsewhere out of office). This shift in perspective can be helpful for your work and I encourage you to take advantage of this time to think freely and critically about your project and current approaches. I do ask that you plan to attend lab meetings in person -- in my experience, remote attendance encourages people to listen (at best), rather than participate, in lab meetings. Also, I ask that you plan to be physically in lab 3-4 days a week. Of course, this can vary week to week and exceptions will be made to fit people\u2019s circumstances. I will sometimes message at evenings, or on weekends. Please do not think this means I expect you to act on, or even read, the message until the next workday unless it\u2019s specifically designated as urgent/time sensitive. It only means that I thought of something relevant to your project and didn\u2019t want to forget. If you'd prefer I not message you outside of working hours (unless urgent), please let me know and I'll schedule these for the next workday. I expect you will be taking vacations. I usually take off from the weekend before Christmas until the weekend after new years, a few days around thanksgiving, a week or two over the summer, and the various official 3-day weekends. I\u2019ll lightly respond to emails during these times, do some reading, maybe some writing. But in general I like to use this time to recharge, spend some time with family and hobbies, and I encourage you all to do the same. For more about work-life balance in academia, please see [Work-life balance] TODO: @dan include link .","title":"Working hours, remote work, and vacation"},{"location":"Policies/meetings/","text":"1-on-1 Meetings All lab members should have a regularly scheduled 1-on-1 meeting with me. This can be weekly or bi-weekly, and will often be used to discuss results and next steps in your project. One strategy that worked well for me during my PhD and postdoc was to come to 1-on-1 meetings with slides. These would include: agenda outline - what do you want to talk about this week quick recap of the current goals, approach, and TL;DR previous meeting figures showing the results from the week ideas for what you think your next steps should be While I generally encourage you to figure out what works best for you, and won\u2019t make this a requirement, I am putting it here as a suggested practice that benefits both of us. It helps me more effectively advise you and where you\u2019re at in your project, and it helps you to make these slides - it makes you go the extra step to generate semi-presentable figures of your results, it prompts you to think of where you\u2019re at and where you should go next, and you'll have many slides to start from when you have to present your work (e.g. in lab meeting). Over time, you become quite good at quickly putting together and presenting effective slide presentations. Of course, we\u2019re not always able to have new results for each meeting - sometimes we\u2019ve been productive, but just thinking; sometimes life has happened and we haven\u2019t made any progress on our projects. That\u2019s ok, and I\u2019m always happy to chat about anything, either why you think things aren\u2019t working, some ideas you've been thinking about, or just generally how things are going. Regardless, it\u2019s good to have the meeting on the calendar and we can always skip a week or have a quick check in if there\u2019s not much to discuss. However, I would encourage you to not get in the habit of pushing back meetings, as a common failure mode of a PhD is a spiral in which you avoid meeting with your advisor because you don\u2019t have results, putting pressure on yourself to have more results for the next meeting, which you then avoid because you don\u2019t have \u201cgood enough\u201d results, \u2026 you see where this goes. This meeting can also be used to discuss career plans, etc. From my point of view, your scheduled 1-on-1 meeting is time set aside in my calendar for you, your research, and your career, and is there for you to use however you think would be most helpful. Please note that 1-on-1 meetings are not the only time I have for you. I am always happy to discuss results: positive or negative, challenges you\u2019re facing, or anything else you want to talk about related to your project, career, or science in general. You can always message me on slack, and if my door is open, please come in! Journal Club As of Spring 2026, journal clubs and lab buisness meetings are every Friday, at 10AM. Format: We follow a rotation picking a paper to read. Paper should be sent to the group 1 week before the journal club (i.e. EOD the previous Friday). There will usually be many interesting papers to pick from in the #papers channel on slack. Each lab member is assigned a figure or two to walk the group through. (This approach makes sure we all read the paper, and avoids the trap of one person reading and presenting while others do not engage.) You should come prepared to explain your assigned figure (no slides needed), answer questions about it, and ask the group about anything you did not understand. If there are supplemental figures or methods associated with your figure, you should be familiar with those as well. It's OK to not understand everything fully - the point of journal club is to talk through and learn together.","title":"Meetings"},{"location":"Policies/meetings/#1-on-1-meetings","text":"All lab members should have a regularly scheduled 1-on-1 meeting with me. This can be weekly or bi-weekly, and will often be used to discuss results and next steps in your project. One strategy that worked well for me during my PhD and postdoc was to come to 1-on-1 meetings with slides. These would include: agenda outline - what do you want to talk about this week quick recap of the current goals, approach, and TL;DR previous meeting figures showing the results from the week ideas for what you think your next steps should be While I generally encourage you to figure out what works best for you, and won\u2019t make this a requirement, I am putting it here as a suggested practice that benefits both of us. It helps me more effectively advise you and where you\u2019re at in your project, and it helps you to make these slides - it makes you go the extra step to generate semi-presentable figures of your results, it prompts you to think of where you\u2019re at and where you should go next, and you'll have many slides to start from when you have to present your work (e.g. in lab meeting). Over time, you become quite good at quickly putting together and presenting effective slide presentations. Of course, we\u2019re not always able to have new results for each meeting - sometimes we\u2019ve been productive, but just thinking; sometimes life has happened and we haven\u2019t made any progress on our projects. That\u2019s ok, and I\u2019m always happy to chat about anything, either why you think things aren\u2019t working, some ideas you've been thinking about, or just generally how things are going. Regardless, it\u2019s good to have the meeting on the calendar and we can always skip a week or have a quick check in if there\u2019s not much to discuss. However, I would encourage you to not get in the habit of pushing back meetings, as a common failure mode of a PhD is a spiral in which you avoid meeting with your advisor because you don\u2019t have results, putting pressure on yourself to have more results for the next meeting, which you then avoid because you don\u2019t have \u201cgood enough\u201d results, \u2026 you see where this goes. This meeting can also be used to discuss career plans, etc. From my point of view, your scheduled 1-on-1 meeting is time set aside in my calendar for you, your research, and your career, and is there for you to use however you think would be most helpful. Please note that 1-on-1 meetings are not the only time I have for you. I am always happy to discuss results: positive or negative, challenges you\u2019re facing, or anything else you want to talk about related to your project, career, or science in general. You can always message me on slack, and if my door is open, please come in!","title":"1-on-1 Meetings"},{"location":"Policies/meetings/#journal-club","text":"As of Spring 2026, journal clubs and lab buisness meetings are every Friday, at 10AM. Format: We follow a rotation picking a paper to read. Paper should be sent to the group 1 week before the journal club (i.e. EOD the previous Friday). There will usually be many interesting papers to pick from in the #papers channel on slack. Each lab member is assigned a figure or two to walk the group through. (This approach makes sure we all read the paper, and avoids the trap of one person reading and presenting while others do not engage.) You should come prepared to explain your assigned figure (no slides needed), answer questions about it, and ask the group about anything you did not understand. If there are supplemental figures or methods associated with your figure, you should be familiar with those as well. It's OK to not understand everything fully - the point of journal club is to talk through and learn together.","title":"Journal Club"},{"location":"Resources/adobe/","text":"We typically use Adobe Illustrator and Photoshop to make scientific figures. To get an Adobe license, you will need to submit a request for Adobe Creative Cloud to IT; see this FAQ section . Licenses run within a fixed period, from August to August, regardless of when you register for one. Students at the Yale School of Medicine receive Adobe CC for free, and students from other departments should request it through their school directly. Other staff (like postdocs, postgrads, technicians, etc.) at YSM can request an upgrade using this form . The $15/year charge listed will be covered by the department. For non YSM-staff, Yale provides the license to staff via Software Library . IT will want you to provide justification for the upgrade; explaining that you need Illustrator/Photoshop to edit scientific figures for posters or publications should be sufficient.","title":"Adobe"},{"location":"Resources/basic_github/","text":"Working on code collaboratively can be a challenge. Managing multiple versions with different functionality can be especially difficult. Version control software allows us to manage collaborative software development by keeping track of different versions and who contributed to what. We will use Git, the most popular framework for version control, and GitHub, a site used to host and manage remote copies of your software. It's important that you become familiar with how to use Git, as it will allow you to collaborate with your colleagues and contribute to meaningful analysis. You should be familiar with: Repositories the add , commit , push commands the status command the difference between branches and forks pull requests and issues how Github integrates with repositories and the command line Here are some basic tutorials you may want to follow: GitHub Hello World tutorial (highly recommended; concise but also text-heavy) GitHub Desktop Tutorial helpful to get started with a graphical user interface (GUI) rather than command line, if you're more comfortable with that. There is also a graphical interface on VSCode. Learn Git Branching (JS Applet) (optional; interactive and visual but perhaps too deep) This Lab-Handbook allows you to make your own changes and push them to be integrated into the content. To do this, clone the repository to your local machine, make your changes, then add, commit and push: git clone https://github.com/LevensteinLab/Lab-Handbook.git git checkout -b BRANCH_NAME (this creates a new branch called BRANCH_NAME and switches to it) Make changes git add . (the dot is code for \"everything in this folder\") git commit -m MESSAGE (replace the message with a one-sentence description of what you changed) git push origin BRANCH_NAME Navigate to the Lab-Handbook GitHub repository You may see a yellow notification bar that indicates your branch is \"ahead\" of the main repository. Submit a pull request to integrate the changes into the final repository Dan will approve it","title":"Basic Github"},{"location":"Resources/booking/","text":"Booking Rooms at 100 College St It's possible to book the conference rooms on our floor for meetings. This is done through Robin . All you need to do is sign in with your Yale Account. There are two ways to book rooms. On the Schedule tab: You can see upcoming public meetings and your meetings on the My Meetings tab. Book rooms by looking at the schedule format (like a Gantt chart), and hovering over the room and time you want. On the Office tab: You can see a layout of the floor, as well as what rooms are available. Book rooms by clicking on a room and viewing available times. Input required details and submit.","title":"Booking Rooms"},{"location":"Resources/booking/#booking-rooms-at-100-college-st","text":"It's possible to book the conference rooms on our floor for meetings. This is done through Robin . All you need to do is sign in with your Yale Account. There are two ways to book rooms. On the Schedule tab: You can see upcoming public meetings and your meetings on the My Meetings tab. Book rooms by looking at the schedule format (like a Gantt chart), and hovering over the room and time you want. On the Office tab: You can see a layout of the floor, as well as what rooms are available. Book rooms by clicking on a room and viewing available times. Input required details and submit.","title":"Booking Rooms at 100 College St"},{"location":"Resources/funding/","text":"Postdoc fellowships Many postdoc fellowships can be found here, along with the time you should try to apply: - https://research-development.zuckermaninstitute.columbia.edu/content/postdoctoral-funding-opportunities Please add to this list as you find more that may be appropriate for the lab","title":"Fellowships/Grants"},{"location":"Resources/gen_ai/","text":"Generative AI Use There has been immense progress in the last 2-3 years regarding the use of language models to assist in writing, learning, and code generation. With this assistance comes a responsibility to use it responsibly and ethically. Below are some compiled resources on how to do. The key points are to take ownership of ideas, code, and analysis generated by LLMs and double check your work by cross-referencing with other sources. Use it transparently and provide proper attribution. LLMs still exhibit phenomena such as sycophancy and hallucination, which may alter the reliability of its generated answers. Resources Living guidelines on the responsible use of generative AI in research (European Commission) Reminder of the Importance of Research Integrity & Use of AI (University of Virginia) Effective and Responsible Use of AI in research (University of Washington, Georgia Tech) Slide from Patrick Mineault on potential pros of AI use (Dan on Bluesky) Should neuroscientists 'vibe code'?(Benjamin Dichter, The Transmitter) GitHub Copilot Access As university-affiliated researchers, we may have access to AI completion tools such as GitHub Copilot. The Pro tier provides a 30-day free trial for researchers/educators. Here are the steps to get access: Visit the GitHub documentation on Copilot Pro access. Click on \"Apply to GitHub Education as a teacher\". Navigate to Education Benefits settings Complete the form and submit. You may need to verify that you have an @yale.edu email address and provide a picture of your ID card. The application will be approved by GitHub admins. You should see a coupon for GitHub Copilot Pro populate in 48-72 hours. This provides access for 30 days. This can get renewed.","title":"GenAI"},{"location":"Resources/gen_ai/#generative-ai-use","text":"There has been immense progress in the last 2-3 years regarding the use of language models to assist in writing, learning, and code generation. With this assistance comes a responsibility to use it responsibly and ethically. Below are some compiled resources on how to do. The key points are to take ownership of ideas, code, and analysis generated by LLMs and double check your work by cross-referencing with other sources. Use it transparently and provide proper attribution. LLMs still exhibit phenomena such as sycophancy and hallucination, which may alter the reliability of its generated answers.","title":"Generative AI Use"},{"location":"Resources/gen_ai/#resources","text":"Living guidelines on the responsible use of generative AI in research (European Commission) Reminder of the Importance of Research Integrity & Use of AI (University of Virginia) Effective and Responsible Use of AI in research (University of Washington, Georgia Tech) Slide from Patrick Mineault on potential pros of AI use (Dan on Bluesky) Should neuroscientists 'vibe code'?(Benjamin Dichter, The Transmitter)","title":"Resources"},{"location":"Resources/gen_ai/#github-copilot-access","text":"As university-affiliated researchers, we may have access to AI completion tools such as GitHub Copilot. The Pro tier provides a 30-day free trial for researchers/educators. Here are the steps to get access: Visit the GitHub documentation on Copilot Pro access. Click on \"Apply to GitHub Education as a teacher\". Navigate to Education Benefits settings Complete the form and submit. You may need to verify that you have an @yale.edu email address and provide a picture of your ID card. The application will be approved by GitHub admins. You should see a coupon for GitHub Copilot Pro populate in 48-72 hours. This provides access for 30 days. This can get renewed.","title":"GitHub Copilot Access"},{"location":"Resources/hpc/","text":"Getting access to the Misha HPC As part of computational research, we will need to dispatch jobs to high-performance computing (HPC) clusters. Access to these clusters gives us stronger power for computationally-intensive tasks like training models. Running the same process on your local machine may take much more time. To get started visit this page for some info about the HPC prepared by the Yale Center for Research Computing (YCRC) specifically for the Wu Tsai Institute. Please also review this github repository with tutorials made by Ms. Ping Luo, a senior staff member who works in our center to manage cluster use. It has more comprehensive information than the preliminary tutorial below. Instructions Fill out the form to access the cluster, noting Dan as the PI from which to get access. You should get access in ~48 hours. Receive email from hpc@yale.edu with your username and instructions on how to login. Choose login method. Access to Misha needs to be done through Secure Shell (SSH). Other clusters have a web interface for logging on (Bouchet, Grace, McCleary, and Milgram). Find the links for the platform, called Open OnDemand (OOD), here . ( First time login only ) Generate your public and private ssh keys. These keys are used to authenticate you during the remote login (i.e. they tell the cluster that you're you.). Keep the private key a secret! Instructions on how to do this can be found here . Note: the example in the documentation uses the RSA encryption scheme, but using the ssh-keygen command on Macs without any additional argument will use the Ed25519 encryption scheme. The key still works and will be stored in something like id_ed25519.pub . Sidebar from Viggy: If you're interested in math, I'd highly recommend reading up on RSA. The RSA public/private key method works beause it's easy to multiply two large prime numbers together, but extremely hard to factor that product back into those primes! ( First time login only ) Upload your public key to the SSH Key Uploader . This allows the cluster to associate it with your netID, which you use to sign in. Login to the cluster. Use the Terminal: Type ssh YOUR_NET_ID@misha.ycrc.yale.edu . It will prompt you for your passcode. After you provide it, it will ask you choose a second authentication option. Type 1 to authenticate via a DUO push notification. Use your IDE: Open VSCode, and click the blue button in the bottom left corner of the screen. It looks like two chevron arrows pointing to each other. Click SSH, and Add New SSH Host Type ssh YOUR_NET_ID@misha.ycrc.yale.edu If it asks you for a config file, select the one with the .ssh/ path (often the first option). This tells VSCode where to look for your private key (which is still protected by your passcode). Enter your passcode when prompted. Type 1 to send a DUO push notification, and accept it. Submit jobs! Type exit to close the connection. About the HPC Consists of multiple groups of computers called nodes . Login node is shared between all users; handles all user logins and is usually excluded from running actual code jobs Compute nodes which are the majority of all the computers in the HPC; where the tasks are performed Can run both interactive and batch jobs on compute notes. Interactive jobs are processes in which you can interactively run programs on the computer, useful for debugging and/or coding. Batch jobs are non-interactive jobs that are run by the node and returned back to you. These can be parallelized, and will also run regardless of whether you are logged in or not. You can have at most 4 interactive sessions at once. Transfer nodes; used for transferring files, accessed via ssh transfer HPC has multiple \"partitions\", which are used for different purposes. There are also special use nodes. devel : default for interactive jobs day : default for batch jobs week : default for long jobs (>24 hours) gpu : nodes with GPU access bigmem : nodes for jobs with large RAM/memory requirements mpi : for highly-parallelized code pi_NAME : PI and lab specific nodes available for purchace from YCPC Cheat Sheet Interactive jobs: salloc to submit interactive job. Flags: -p or --partition= (default devel /interactive) -t or --time= (DD-HH:MM:SS or DD-HH time limit) --mem-per-cpu= (default 5gb per cpu) module load to load common software also module list to list available software module purge to remove all currently loaded software Example code: salloc -t 1:00:00 module load miniconda conda create -n env_name python=3.9 jupyter pandas conda activate env_name conda install pkg1 pkg2 module load miniconda conda activate env_name Batch jobs: sbatch to submit batch job. Flags: -j or --job-name= (job name) -o or --output= (output file name) --mail-user (email address to receive alerts about job completions, default: Yale address) --mail-type=ALL (receive email notifs at beginning and end of job) squeue --me (get status of all your submitted jobs) seff JOBID (get job stats when done e.g. CPU usage, time run) scancel JOBID (cancel job) htop -u NETID (view all current processes under your name) Misc commands: getquota (see remaining storage) dsq for large numbers of identical jobs Example code: #!/bin/bash #SBATCH -J example_job #SBATCH -p dat #SBATCH -t 12:00:00 #SBATCH --mail-type=ALL module purge module load miniconda conda activate my_env python my_python.py Example Use Case: Cloning Remote Repository At first, attempting to clone a repository in the standard way (e.g. git clone https://github.com/LevensteinLab/Lab-Handbook.git ) may not work. This is because GitHub doesn't know how to handle a request from a remote computer. You must first authenticate yourself. We can repeat the same process we used to authenticate ourselves for the cluster, but for GitHub, which offers the ability to add SSH keys. While logged into the cluster, again run ssh-keygen . Click enter to accept the default directory for where the keys will be stored. Choose a passphrase. You will need to remember this, as it provides access to your private key. Navigate to that directory and open the public key. This may look something like: cd /gpfs/radev/home/vv266/.ssh/ followed by cat id_ed25519.pub Copy that text and open your GitHub profile. Navigate to Settings > SSH and GPG keys > New SSH key . Then paste your public key into the box. Return to the HPC and type ssh -T git@github.com . After you type in your passphrase, you should see a message like Hi vviggyy! You've successfully authenticated, but GitHub does not provide shell access. You should now be able to clone repositories into the HPC environment. When you want to do so, visit the repository website, click the green <> Code button, and tap \"SSH\" (NOT the HTTPS button!) Use this URL when cloning e.g. git clone git@github.com:LevensteinLab/Lab-Handbook.git Set up a conda environment like above to run it! Reference: Introduction to HPC Clusters (YouTube Video) (1:16 hr workshop video going over SLURM and how to log-in) Getting Started page Documentation Page . Submit help requests or attend drop-in office hours (via Zoom) on Wednesdays at 11am-12pm Check out info on all clusters offered by the YCRC . They're named after famous academics. Any potential system outages can be checked here . Common SLURM commands for interacting with jobs and the scheduler YCRC HPC Policies ( make sure to read this before requesting an account )","title":"HPC"},{"location":"Resources/hpc/#getting-access-to-the-misha-hpc","text":"As part of computational research, we will need to dispatch jobs to high-performance computing (HPC) clusters. Access to these clusters gives us stronger power for computationally-intensive tasks like training models. Running the same process on your local machine may take much more time. To get started visit this page for some info about the HPC prepared by the Yale Center for Research Computing (YCRC) specifically for the Wu Tsai Institute. Please also review this github repository with tutorials made by Ms. Ping Luo, a senior staff member who works in our center to manage cluster use. It has more comprehensive information than the preliminary tutorial below.","title":"Getting access to the Misha HPC"},{"location":"Resources/hpc/#instructions","text":"Fill out the form to access the cluster, noting Dan as the PI from which to get access. You should get access in ~48 hours. Receive email from hpc@yale.edu with your username and instructions on how to login. Choose login method. Access to Misha needs to be done through Secure Shell (SSH). Other clusters have a web interface for logging on (Bouchet, Grace, McCleary, and Milgram). Find the links for the platform, called Open OnDemand (OOD), here . ( First time login only ) Generate your public and private ssh keys. These keys are used to authenticate you during the remote login (i.e. they tell the cluster that you're you.). Keep the private key a secret! Instructions on how to do this can be found here . Note: the example in the documentation uses the RSA encryption scheme, but using the ssh-keygen command on Macs without any additional argument will use the Ed25519 encryption scheme. The key still works and will be stored in something like id_ed25519.pub . Sidebar from Viggy: If you're interested in math, I'd highly recommend reading up on RSA. The RSA public/private key method works beause it's easy to multiply two large prime numbers together, but extremely hard to factor that product back into those primes! ( First time login only ) Upload your public key to the SSH Key Uploader . This allows the cluster to associate it with your netID, which you use to sign in. Login to the cluster. Use the Terminal: Type ssh YOUR_NET_ID@misha.ycrc.yale.edu . It will prompt you for your passcode. After you provide it, it will ask you choose a second authentication option. Type 1 to authenticate via a DUO push notification. Use your IDE: Open VSCode, and click the blue button in the bottom left corner of the screen. It looks like two chevron arrows pointing to each other. Click SSH, and Add New SSH Host Type ssh YOUR_NET_ID@misha.ycrc.yale.edu If it asks you for a config file, select the one with the .ssh/ path (often the first option). This tells VSCode where to look for your private key (which is still protected by your passcode). Enter your passcode when prompted. Type 1 to send a DUO push notification, and accept it. Submit jobs! Type exit to close the connection.","title":"Instructions"},{"location":"Resources/hpc/#about-the-hpc","text":"Consists of multiple groups of computers called nodes . Login node is shared between all users; handles all user logins and is usually excluded from running actual code jobs Compute nodes which are the majority of all the computers in the HPC; where the tasks are performed Can run both interactive and batch jobs on compute notes. Interactive jobs are processes in which you can interactively run programs on the computer, useful for debugging and/or coding. Batch jobs are non-interactive jobs that are run by the node and returned back to you. These can be parallelized, and will also run regardless of whether you are logged in or not. You can have at most 4 interactive sessions at once. Transfer nodes; used for transferring files, accessed via ssh transfer HPC has multiple \"partitions\", which are used for different purposes. There are also special use nodes. devel : default for interactive jobs day : default for batch jobs week : default for long jobs (>24 hours) gpu : nodes with GPU access bigmem : nodes for jobs with large RAM/memory requirements mpi : for highly-parallelized code pi_NAME : PI and lab specific nodes available for purchace from YCPC","title":"About the HPC"},{"location":"Resources/hpc/#cheat-sheet","text":"Interactive jobs: salloc to submit interactive job. Flags: -p or --partition= (default devel /interactive) -t or --time= (DD-HH:MM:SS or DD-HH time limit) --mem-per-cpu= (default 5gb per cpu) module load to load common software also module list to list available software module purge to remove all currently loaded software Example code: salloc -t 1:00:00 module load miniconda conda create -n env_name python=3.9 jupyter pandas conda activate env_name conda install pkg1 pkg2 module load miniconda conda activate env_name Batch jobs: sbatch to submit batch job. Flags: -j or --job-name= (job name) -o or --output= (output file name) --mail-user (email address to receive alerts about job completions, default: Yale address) --mail-type=ALL (receive email notifs at beginning and end of job) squeue --me (get status of all your submitted jobs) seff JOBID (get job stats when done e.g. CPU usage, time run) scancel JOBID (cancel job) htop -u NETID (view all current processes under your name) Misc commands: getquota (see remaining storage) dsq for large numbers of identical jobs Example code: #!/bin/bash #SBATCH -J example_job #SBATCH -p dat #SBATCH -t 12:00:00 #SBATCH --mail-type=ALL module purge module load miniconda conda activate my_env python my_python.py","title":"Cheat Sheet"},{"location":"Resources/hpc/#example-use-case-cloning-remote-repository","text":"At first, attempting to clone a repository in the standard way (e.g. git clone https://github.com/LevensteinLab/Lab-Handbook.git ) may not work. This is because GitHub doesn't know how to handle a request from a remote computer. You must first authenticate yourself. We can repeat the same process we used to authenticate ourselves for the cluster, but for GitHub, which offers the ability to add SSH keys. While logged into the cluster, again run ssh-keygen . Click enter to accept the default directory for where the keys will be stored. Choose a passphrase. You will need to remember this, as it provides access to your private key. Navigate to that directory and open the public key. This may look something like: cd /gpfs/radev/home/vv266/.ssh/ followed by cat id_ed25519.pub Copy that text and open your GitHub profile. Navigate to Settings > SSH and GPG keys > New SSH key . Then paste your public key into the box. Return to the HPC and type ssh -T git@github.com . After you type in your passphrase, you should see a message like Hi vviggyy! You've successfully authenticated, but GitHub does not provide shell access. You should now be able to clone repositories into the HPC environment. When you want to do so, visit the repository website, click the green <> Code button, and tap \"SSH\" (NOT the HTTPS button!) Use this URL when cloning e.g. git clone git@github.com:LevensteinLab/Lab-Handbook.git Set up a conda environment like above to run it!","title":"Example Use Case: Cloning Remote Repository"},{"location":"Resources/hpc/#reference","text":"Introduction to HPC Clusters (YouTube Video) (1:16 hr workshop video going over SLURM and how to log-in) Getting Started page Documentation Page . Submit help requests or attend drop-in office hours (via Zoom) on Wednesdays at 11am-12pm Check out info on all clusters offered by the YCRC . They're named after famous academics. Any potential system outages can be checked here . Common SLURM commands for interacting with jobs and the scheduler YCRC HPC Policies ( make sure to read this before requesting an account )","title":"Reference:"},{"location":"Resources/mailing_lists/","text":"Mailing lists/groups at Yale Mailing lists/groups you may wish to sign up for/get added to, and how. Click the links to be redirected to submission forms. For most, you'll need to input your email, name, and the answer to a bot-prevention question. You may also choose an optional password to prevent anyone from messing with your subscription. *=Strongly recommended Mailing Lists Neuroscience mailing list Interdepartmental Neuroscience Program (INP) mailing list * Wu Tsai Institute (WTI) mailing list * WTI Trainees mailing list Research in Progress (RIP) mailing list - Ask Dan to email on your behalf * WTI NeuroAI Journal Club mailing list APplied PHilosophy In NEuroscience (APHINE) Quantitative Biology (QBio) talks Foundations of Data Science Institute talks - visit subscribe.yale.edu and find \"FDS Announcements\" under the \"Research Administration\" category It's also possible to check out all mailman@yale links or manage your subscriptions with the links below: All mailman.yale.edu mailing lists Manage subscriptions ( This doesn't seem to manage ALL subscriptions but it does show many ) Slack Workspaces WTI Slack - Fill out request form Levenstein Lab Slack - Ask Dan to add you","title":"Mailing Lists"},{"location":"Resources/mailing_lists/#mailing-listsgroups-at-yale","text":"Mailing lists/groups you may wish to sign up for/get added to, and how. Click the links to be redirected to submission forms. For most, you'll need to input your email, name, and the answer to a bot-prevention question. You may also choose an optional password to prevent anyone from messing with your subscription. *=Strongly recommended","title":"Mailing lists/groups at Yale"},{"location":"Resources/mailing_lists/#mailing-lists","text":"Neuroscience mailing list Interdepartmental Neuroscience Program (INP) mailing list * Wu Tsai Institute (WTI) mailing list * WTI Trainees mailing list Research in Progress (RIP) mailing list - Ask Dan to email on your behalf * WTI NeuroAI Journal Club mailing list APplied PHilosophy In NEuroscience (APHINE) Quantitative Biology (QBio) talks Foundations of Data Science Institute talks - visit subscribe.yale.edu and find \"FDS Announcements\" under the \"Research Administration\" category It's also possible to check out all mailman@yale links or manage your subscriptions with the links below: All mailman.yale.edu mailing lists Manage subscriptions ( This doesn't seem to manage ALL subscriptions but it does show many )","title":"Mailing Lists"},{"location":"Resources/mailing_lists/#slack-workspaces","text":"WTI Slack - Fill out request form Levenstein Lab Slack - Ask Dan to add you","title":"Slack Workspaces"},{"location":"Resources/mental_health/","text":"Mental health et al My hope is that you won\u2019t need to use these, but I think everyone should be aware that they exist, and how to access them, in case you or someone you know can be helped by them https://yalehealth.yale.edu/department/mental-health-counseling https://your.yale.edu/working-at-yale/benefits/your-well-being https://chaplain.yale.edu If you know of more, please add them","title":"Mental Health"},{"location":"Resources/mental_health/#mental-health-et-al","text":"My hope is that you won\u2019t need to use these, but I think everyone should be aware that they exist, and how to access them, in case you or someone you know can be helped by them https://yalehealth.yale.edu/department/mental-health-counseling https://your.yale.edu/working-at-yale/benefits/your-well-being https://chaplain.yale.edu If you know of more, please add them","title":"Mental health et al"},{"location":"Resources/printers/","text":"The driver for the printer can be found here: User Support Page ECOSYS PA4000cx Support Page And instructions on how to install it can be found here: Mac Driver Setup Guide Office Printer Information: Location : Stationary nook in front of 1126B, 11th Floor, 100 College St. Printer Model : ECOSYS PA4000cx Printer Name : YUCOLL100X01126AM1.MED.YALE.INTERNAL Printer Setup Tutorial (Step-by-step): Download the driver for the printer This can be done through the \"Web Installer\" option, which will download an installer that picks the right driver for you, or the \"Printer Driver\" option, which will download the driver itself. Ensure you are downloading the one that corresponds to the model above Connect to the printer through your device For Mac: This is Settings > Printers & Scanners > Add Printer, Scanner, or Fax Click the IP button (looks like a litle globe) Add the name of the printer ( YUCOLL100X01126AM1.MED.YALE.INTERNAL ) into the Address field, and a text line will show underneath saying Valid and complete host name or address . The Name , Location , and Use fields will all populate in the box below. You should see: Name: YUCOLL100X01126AM1.MED.YALE.INTERNAL Location: 100 COLLEGE RM 1126 Use: Kyocera ECOSYS PA4000cx KPDL Optionally: change Protocol to Line Printer Daemon - LPD format. This is recommended by the manual. Click the Add button. You should be able to print! NOTE: You must be connected to the YaleSecure network to use the printer over wireless. If you are not connected, the printer will fail. The printer is already connected to YaleSecure so you should not need to touch the WiFi settings.","title":"Printing"},{"location":"Resources/prnn_tutorial/","text":"Predictive RNNs There are some extra steps in managing the requirements needed for the Predictive RNN project. This guide should help you get everything set up on Misha. Ensure you have an account on Misha, and log on. Make sure to allocate an interactive session (e.g. salloc -t 2:00:00 )! If are using the VS Code Proxy (as described on the vs_code.md page), you're already on a compute node. Make sure you've also set up SSH cloning from the cluster, because you'll need to clone repositories into your storage. We're using SSH clone links from here out. See the page on HPCs for more information on this. Clone the pRNN package into your project folder. This is accessible by typing cd ~/../../project/levenstein/YOUR_NETID/ . This brings you to the /gpfs/radev/project/levenstein/YOUR_NETID . git clone git@github.com:LevensteinLab/pRNN.git \ud83d\udc41\ufe0f Watch the repository so you can be notified of any updates! Also clone the following repository into that project directory: Farama Foundation version of minigrid. This is the most up-to-date version. ( git clone git@github.com:Farama-Foundation/Minigrid.git ) Create a conda environment with Python 3.9. Misha doesn't come with Python 3.9 out of the box, and we need this version for later dependencies. Type module load miniconda to ensure conda is loaded for use. Run conda create -n prnn_tutorial python=3.9 to make an environment called prnn_tutorial with python 3.9 installed. Activate it ( conda activate prnn_tutorial ). In the project folder, create your own separate repo for your work. We recommend using a template such as Patrick Mineault's true-neutral-cookiecutter to model the repository after. pip install cookiecutter cookiecutter gh:patrickmineault/true-neutral-cookiecutter It will prompt you for input regarding the name of the repository. Now, we need to populate our environment with the correct packages. Some of them depend on an older version of pip, so it's important to do the steps in order. Run the following commands: pip install \"pip<24.1\" setuptools==59.5.0 wheel==0.37.0 pip install gym==0.21.0 --no-binary gym pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --no-cache-dir We'll also need to install the external repository from step 3 into environment. pip3 install -e ~/../../project/levenstein/YOUR_NETID/Minigrid Install the pRNN package itself into the environment. Navigate to the repository, then pip install -e . Make sure that the jupyter notebook kernel can recognize this environment. pip install ipykernel Run ipython kernel install --user --name=prnn_tutorial . To allow jupyter notebooks to pick it up. If you run jupyter kernelspec list , you should see prnn_tutorial as an option. You may need to restart your VSCode or kernel here. If you're on VSCode, you can do this fast with Cmd + Shift + P to open the Command Palette and then Developer: Reload Window . Your environment should be all set to run example code provided with the package, or to start going through the tutorials. The quickstart tutorial can be found here . This contains an example training run. If you would like to run through quickstart interactively, you will need to copy pRNN/examples/tutorial.ipynb to your prnn_tutorial folder. This can be done with rsync -r ../pRNN/examples/ .","title":"pRNN Tutorial"},{"location":"Resources/prnn_tutorial/#predictive-rnns","text":"There are some extra steps in managing the requirements needed for the Predictive RNN project. This guide should help you get everything set up on Misha. Ensure you have an account on Misha, and log on. Make sure to allocate an interactive session (e.g. salloc -t 2:00:00 )! If are using the VS Code Proxy (as described on the vs_code.md page), you're already on a compute node. Make sure you've also set up SSH cloning from the cluster, because you'll need to clone repositories into your storage. We're using SSH clone links from here out. See the page on HPCs for more information on this. Clone the pRNN package into your project folder. This is accessible by typing cd ~/../../project/levenstein/YOUR_NETID/ . This brings you to the /gpfs/radev/project/levenstein/YOUR_NETID . git clone git@github.com:LevensteinLab/pRNN.git \ud83d\udc41\ufe0f Watch the repository so you can be notified of any updates! Also clone the following repository into that project directory: Farama Foundation version of minigrid. This is the most up-to-date version. ( git clone git@github.com:Farama-Foundation/Minigrid.git ) Create a conda environment with Python 3.9. Misha doesn't come with Python 3.9 out of the box, and we need this version for later dependencies. Type module load miniconda to ensure conda is loaded for use. Run conda create -n prnn_tutorial python=3.9 to make an environment called prnn_tutorial with python 3.9 installed. Activate it ( conda activate prnn_tutorial ). In the project folder, create your own separate repo for your work. We recommend using a template such as Patrick Mineault's true-neutral-cookiecutter to model the repository after. pip install cookiecutter cookiecutter gh:patrickmineault/true-neutral-cookiecutter It will prompt you for input regarding the name of the repository. Now, we need to populate our environment with the correct packages. Some of them depend on an older version of pip, so it's important to do the steps in order. Run the following commands: pip install \"pip<24.1\" setuptools==59.5.0 wheel==0.37.0 pip install gym==0.21.0 --no-binary gym pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --no-cache-dir We'll also need to install the external repository from step 3 into environment. pip3 install -e ~/../../project/levenstein/YOUR_NETID/Minigrid Install the pRNN package itself into the environment. Navigate to the repository, then pip install -e . Make sure that the jupyter notebook kernel can recognize this environment. pip install ipykernel Run ipython kernel install --user --name=prnn_tutorial . To allow jupyter notebooks to pick it up. If you run jupyter kernelspec list , you should see prnn_tutorial as an option. You may need to restart your VSCode or kernel here. If you're on VSCode, you can do this fast with Cmd + Shift + P to open the Command Palette and then Developer: Reload Window . Your environment should be all set to run example code provided with the package, or to start going through the tutorials. The quickstart tutorial can be found here . This contains an example training run. If you would like to run through quickstart interactively, you will need to copy pRNN/examples/tutorial.ipynb to your prnn_tutorial folder. This can be done with rsync -r ../pRNN/examples/ .","title":"Predictive RNNs"},{"location":"Resources/purchases/","text":"Making Purchases Generally, either Dan or Viggy will handle purchases for the lab. In this past, this included the shared coat rack, monitors for new members, cables, etc. Purchases/Requisitions are done through Workday . You can check the catalogue of items by opening Workday and searching \"Create Requisition\". If you click OK to accept the default fields, you will see an option to \"Connect to Supplier Website\". There, you can choose from a list of suppliers, or search for products directly. Once you find the item you're looking for, confirm it with Dan, then send the supplier and product information to Viggy. If you'd like to make purchases yourself, you may need to take a few Workday Learning courses. If you have any boxes to dispose of, please leave them by the trash can in front of Dan's office, rather than in the main WTI lounge. This was particularly requested by the custodial staff.","title":"Purchases"},{"location":"Resources/purchases/#making-purchases","text":"Generally, either Dan or Viggy will handle purchases for the lab. In this past, this included the shared coat rack, monitors for new members, cables, etc. Purchases/Requisitions are done through Workday . You can check the catalogue of items by opening Workday and searching \"Create Requisition\". If you click OK to accept the default fields, you will see an option to \"Connect to Supplier Website\". There, you can choose from a list of suppliers, or search for products directly. Once you find the item you're looking for, confirm it with Dan, then send the supplier and product information to Viggy. If you'd like to make purchases yourself, you may need to take a few Workday Learning courses. If you have any boxes to dispose of, please leave them by the trash can in front of Dan's office, rather than in the main WTI lounge. This was particularly requested by the custodial staff.","title":"Making Purchases"},{"location":"Resources/recommended_reading/","text":"Recommended Reading Some recommended foundational papers and reviews to get acquainted with selected topics of interest to the lab Sleep Sleep-dependent memory consolidation , Stickgold R, 2005, Nature The memory function of sleep , Diekelmann S & Born J, 2010, Nat Rev Neurosci Overlapping memory replay during sleep builds cognitive schemata , Lewis PA & Durrant SJ, 2011, Trends Cogn Sci About sleep\u2019s role in memory , Rasch B & Born J, 2013, Physiol Rev Sleep and synaptic plasticity in the developing and adult brain , Frank MG, 2014, Curr Top Behav Neurosci Mechanisms of systems memory consolidation during sleep , Klinzing JG et al, 2019, Nat Neurosci Experience and sleep-dependent synaptic plasticity: from structure to activity , Sun L et al, 2020, Philos Trans R Soc B Sleep \u2014 a brain state serving systems memory consolidation , Brodt S et al, 2023, Neuron Sleep\u2019s contribution to memory formation , Lutz ND et al, 2026, Physiol Rev Memory consolidation Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory , McClelland JL et al, 1995, Psychol Rev Artificial Neural Networks (ANNs) https://www.sciencedirect.com/science/article/pii/S0896627320307054 neuroAI https://www.nature.com/articles/s41583-023-00705-w https://www.nature.com/articles/s41593-019-0520-2 Replay in brains and ANNs https://www.cell.com/trends/neurosciences/abstract/S0166-2236(21)00144-2 https://direct.mit.edu/neco/article-abstract/33/11/2908/107071/Replay-in-Deep-Learning-Current-Approaches-and https://www.tandfonline.com/doi/abs/10.1080/095400996116910 https://www.nature.com/articles/s41467-020-17866-2 hippocampus https://pmc.ncbi.nlm.nih.gov/articles/PMC4648295/ Hippocampus/MEC - recent models The hippocampus as a predictive map , Stachenfeld KL et al, 2017, Nat Neurosci Vector-based navigation using grid-like representations in artificial agents , Banino A et al, 2018, Nature The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation , Whittington JCR et al, 2020, Cell A model of egocentric to allocentric understanding in mammalian brains , Uria B et al, 2020, bioRxiv Place cells may simply be memory cells: Memory compression leads to spatial tuning and history dependence , Benna MK et al, 2021, Proc Natl Acad Sci U S A Predictive learning as a network mechanism for extracting low-dimensional latent space representations , Recanatesi S et al, 2021, Nat Commun Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps , George D et al, 2021, Nat Commun A unified theory for the computational and mechanistic origins of grid cells , Sorscher B et al, 2023, Neuron Self-Supervised Learning of Representations for Space Generates Multi-Modular Grid Cells , Schaeffer R et al, 2023, NeurIPS Episodic and associative memory from spatial scaffolds in the hippocampus , Chandra S et al, 2025, Nature Neural population dynamics, manifolds, et al Mante et al., 2013, Nature. Context-dependent computation by recurrent dynamics in prefrontal cortex Sussillo et al, 2013, Neural Computation. Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks Sadtler et al, 2014, Nature. Neural constraints on learning Sussillo et al, 2015, Nature Neuroscience. A neural network that finds a naturalistic solution for the production of muscle activity Gallego et al, 2017, Neuron . Neural Manifolds for the Control of Movement Mastrogiuseppe & Ostojic, 2018, Neuron . Linking Connectivity, Dynamics, and Computations in Low-Rank Recurrent Neural Networks Saxena & Cunningham, 2019, Current Opinion in Neurobiology . Towards the neural population doctrine Inagaki et al, 2019, Nature. Discrete attractor dynamics underlies persistent activity in the frontal cortex Chaudhuri et al, 2019, Nature Neuroscience . The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep Yang et al, 2019, Nature Neuroscience . Task representations in neural networks trained to perform many cognitive tasks Vyas et al, 2020, Annual Review of Neuroscience . Computation Through Neural Population Dynamics Barack et al, 2021, Nat Rev Neurosci . Two views on the cognitive brain Kriegeskorte et al, 2021, Nature Reviews Neuroscience . Neural tuning and representational geometry Jazayeri & Ostojic, 2021, Current Opinion in Neurobiology. Interpreting neural computations by examining intrinsic and embedding dimensionality of neural activity DePasquale et al, 2023, Neuron . The centrality of population-level factors to network computation is demonstrated by a versatile approach for training spiking networks Langdon et al, 2023, Nature Reviews Neuroscience. A unifying perspective on neural manifolds and circuits for cognition Driscoll et al, 2024, Nature Neuroscience . Flexible multitask computation in recurrent networks utilizes shared dynamical motifs Genkin et al, 2025, Nature. The dynamics and geometry of choice in the premotor cortex Langdon et al, 2025, Nature Neuroscience . Latent circuit inference from heterogeneous neural responses during cognitive tasks General - scientific process https://web.stanford.edu/~fukamit/schwartz-2008.pdf https://www.nature.com/articles/s41587-023-02074-2 modeling and theory https://pubmed.ncbi.nlm.nih.gov/39257366/ https://www.jstor.org/stable/184253","title":"Recommended Reading"},{"location":"Resources/recommended_reading/#recommended-reading","text":"Some recommended foundational papers and reviews to get acquainted with selected topics of interest to the lab Sleep Sleep-dependent memory consolidation , Stickgold R, 2005, Nature The memory function of sleep , Diekelmann S & Born J, 2010, Nat Rev Neurosci Overlapping memory replay during sleep builds cognitive schemata , Lewis PA & Durrant SJ, 2011, Trends Cogn Sci About sleep\u2019s role in memory , Rasch B & Born J, 2013, Physiol Rev Sleep and synaptic plasticity in the developing and adult brain , Frank MG, 2014, Curr Top Behav Neurosci Mechanisms of systems memory consolidation during sleep , Klinzing JG et al, 2019, Nat Neurosci Experience and sleep-dependent synaptic plasticity: from structure to activity , Sun L et al, 2020, Philos Trans R Soc B Sleep \u2014 a brain state serving systems memory consolidation , Brodt S et al, 2023, Neuron Sleep\u2019s contribution to memory formation , Lutz ND et al, 2026, Physiol Rev Memory consolidation Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory , McClelland JL et al, 1995, Psychol Rev Artificial Neural Networks (ANNs) https://www.sciencedirect.com/science/article/pii/S0896627320307054 neuroAI https://www.nature.com/articles/s41583-023-00705-w https://www.nature.com/articles/s41593-019-0520-2 Replay in brains and ANNs https://www.cell.com/trends/neurosciences/abstract/S0166-2236(21)00144-2 https://direct.mit.edu/neco/article-abstract/33/11/2908/107071/Replay-in-Deep-Learning-Current-Approaches-and https://www.tandfonline.com/doi/abs/10.1080/095400996116910 https://www.nature.com/articles/s41467-020-17866-2 hippocampus https://pmc.ncbi.nlm.nih.gov/articles/PMC4648295/ Hippocampus/MEC - recent models The hippocampus as a predictive map , Stachenfeld KL et al, 2017, Nat Neurosci Vector-based navigation using grid-like representations in artificial agents , Banino A et al, 2018, Nature The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation , Whittington JCR et al, 2020, Cell A model of egocentric to allocentric understanding in mammalian brains , Uria B et al, 2020, bioRxiv Place cells may simply be memory cells: Memory compression leads to spatial tuning and history dependence , Benna MK et al, 2021, Proc Natl Acad Sci U S A Predictive learning as a network mechanism for extracting low-dimensional latent space representations , Recanatesi S et al, 2021, Nat Commun Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps , George D et al, 2021, Nat Commun A unified theory for the computational and mechanistic origins of grid cells , Sorscher B et al, 2023, Neuron Self-Supervised Learning of Representations for Space Generates Multi-Modular Grid Cells , Schaeffer R et al, 2023, NeurIPS Episodic and associative memory from spatial scaffolds in the hippocampus , Chandra S et al, 2025, Nature Neural population dynamics, manifolds, et al Mante et al., 2013, Nature. Context-dependent computation by recurrent dynamics in prefrontal cortex Sussillo et al, 2013, Neural Computation. Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks Sadtler et al, 2014, Nature. Neural constraints on learning Sussillo et al, 2015, Nature Neuroscience. A neural network that finds a naturalistic solution for the production of muscle activity Gallego et al, 2017, Neuron . Neural Manifolds for the Control of Movement Mastrogiuseppe & Ostojic, 2018, Neuron . Linking Connectivity, Dynamics, and Computations in Low-Rank Recurrent Neural Networks Saxena & Cunningham, 2019, Current Opinion in Neurobiology . Towards the neural population doctrine Inagaki et al, 2019, Nature. Discrete attractor dynamics underlies persistent activity in the frontal cortex Chaudhuri et al, 2019, Nature Neuroscience . The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep Yang et al, 2019, Nature Neuroscience . Task representations in neural networks trained to perform many cognitive tasks Vyas et al, 2020, Annual Review of Neuroscience . Computation Through Neural Population Dynamics Barack et al, 2021, Nat Rev Neurosci . Two views on the cognitive brain Kriegeskorte et al, 2021, Nature Reviews Neuroscience . Neural tuning and representational geometry Jazayeri & Ostojic, 2021, Current Opinion in Neurobiology. Interpreting neural computations by examining intrinsic and embedding dimensionality of neural activity DePasquale et al, 2023, Neuron . The centrality of population-level factors to network computation is demonstrated by a versatile approach for training spiking networks Langdon et al, 2023, Nature Reviews Neuroscience. A unifying perspective on neural manifolds and circuits for cognition Driscoll et al, 2024, Nature Neuroscience . Flexible multitask computation in recurrent networks utilizes shared dynamical motifs Genkin et al, 2025, Nature. The dynamics and geometry of choice in the premotor cortex Langdon et al, 2025, Nature Neuroscience . Latent circuit inference from heterogeneous neural responses during cognitive tasks General - scientific process https://web.stanford.edu/~fukamit/schwartz-2008.pdf https://www.nature.com/articles/s41587-023-02074-2 modeling and theory https://pubmed.ncbi.nlm.nih.gov/39257366/ https://www.jstor.org/stable/184253","title":"Recommended Reading"},{"location":"Resources/science_general/","text":"The term \"research\" is a broad way to describe many different skills. Designing scientifically-sound experiments, testing your hypotheses, and analyzing data are only part of the equation. Research is also about asking the right questions, choosing which problems to work on, and knowing when to move on. Here are a few highly-recommended reads on how to do good research and what types of expectations are reasonable for yourself. How to develop good research questions (Nature Human Behavior, Megan A. K. Peters) - Article outlining the \"phases\" of how to come up with a good direction and common pitfalls to avoid. How to choose a good scientific problem You and Your Research (Dr. Richard Hamming, retired Bell Labs scientist) - Transcript of a talk given to scientists at the prolific Bell Labs, on the question \"Why do so few scientists make significant contributions and so many are forgotten in the long run?\". How to make your research career impactful How a Ph.D. is like riding a bike (Science blog, Ehsan Hamzehpoor) - Article on expectations during a Ph.D. and what the purpose of one is. Advice for Applying to PhD Programs - Anita Devineni's blog post on applying to grad school How to Apply for Postdoctoral Positions and Choose the Right One - Anita's blog post on choosing a postdoc The Genius Fallacy The illustrated guide to a Ph.D. Tough love: an insensitive guide to thriving in your PhD You're only human: a six-step strategy to surviving your PhD Add more yourself...!","title":"Doing Science"},{"location":"Resources/travel/","text":"To book travel and accommodation for conferences, use World Travel/Concur, Yale's platform for business travel. See here for more information. You can log into the Concur website here . There is a training in Workday called \"Booking Federally Sponsored Travel with World Travel\" that you should complete in order to understand the restrictions on booking travel when using federal funds. You have a few options when it comes to airports: Bradley International Airport (BDL) in Hartford, CT: drive/Uber Newark International Airport (EWR) in Newark, NJ: direct Amtrak train from New Haven John F. Kennedy Airport (JFK) in Queens, NYC: Amtrak to LIRR or E train to AirTrain LaGuardia Airport (LGA) in Queens, NYC: Metro-North to Harlem-125th Street, then Uber or M60+ bus The three NYC airports (including EWR) are generally far cheaper and better connected. The direct Amtrak train from New Haven to Newark/EWR makes that the most convenient option. You can book Amtrak tickets in Concur (you should book them in advance) or use the TrainTime App to buy Metro-North/LIRR tickets (less important to buy in advance). To navigate the MTA (NYC's public transit system) use Google Maps or e.g. CityMapper for real-time arrival info. The MTA has tap-to-pay terminals, so you can purchase a ticket on-site using your card or phone.","title":"Travel"},{"location":"Resources/vpn/","text":"Some of Yale's internal tools, such as the cluster, are only available on the Yale network. If you are off campus, you will need to use a VPN. For Windows and Mac OS X, download the Cisco AnyConnect VPN Client from the ITS Software Library . See this guide for Linux and for the full instructions, which will be briefly outlined below. Once you have installed the Cisco software, type in the server address: access.yale.edu and click connect. This should open an authentication tab in your browser, where you will be able to log in using your Yale net ID and password.","title":"VPN"},{"location":"Resources/vs_code/","text":"To get started with VS Code try a tutorial, such as this one . The program itself will also give you some tips. Some basic tips to get started: 1. Link VS Code with your GitHub account 2. Open a repository, such as Lab-Handbook 3. Try out the terminal (e.g. try echo $SHELL to see which shell your computer runs by default) 4. Install the Python extension 5. Create an environment 6. Use the debugger. You can copy Resources/debug_me.py to try it out! If you want, you can create a new project repo that you will also use for the pytorch tutorial as part of your first project. To use VS Code with the cluster off campus, you will need to use a VPN (see Resources/hpc.md for more information on using the cluster and Resources/vpn.md to configure the VPN). To connect VS Code to the Misha cluster: 1. Go to the Misha OnDemand website . 2. Start a VS Code Proxy from the Interactive Apps section. - Configure the proxy according to your needs (e.g. time, memory, number of cores, and type of partition) - Launch the session. It may take a few minutes depending on how busy the cluster is - If it's your first time using the VS Code proxy, follow the instructions listed to configure your ~/.ssh/config file 3. Once the proxy is running, open the Command Palette in VS Code (Mac: Cmd + Shift + P; Windows: Ctrl + Shift + P) and type Remote-SSH: Connect to Host... , then choose vscode-server . 4. Complete the 2-factor authentication using Duo or a phone call (do this quickly or it will time out). If successful you should see SSH: vscode-server on the bottom left corner.","title":"VS Code"},{"location":"Resources/writing/","text":"Writing Over the course of your time in the lab we will write a lot together. Manuscripts, fellowship/grant applications, conference abstracts\u2026 Writing is a craft, and scientific writing is a specific kind of writing. Writing effectively takes a lot of time and work. From the get go, I recommend everyone watch this lecture on how to write well . Watch it now, before you have to write anything. And watch it again in a year or two. Part of your training in the lab is to improve your writing skills, and IMO it\u2019s one of the most important parts. Remember: your three main outputs in the lab are figures, ideas, and code. Writing is a tool for developing your ideas, and it\u2019s the most tangible way you will communicate those ideas. Writing well will get you a job, and it will improve your science, because writing is a thinking tool as much as it\u2019s a communication tool (WARNING! these are not the same, see the lecture \ud83d\ude09). A heads up: when you get a draft back from me, it will likely have a lot of red ink. More red ink is good . Make sure to give yourself, and me, enough time to work on drafts together (e.g. I want to see abstract drafts a week before conference submission). For any document you submit, expect a lot of comments/suggestions and few rounds of back-and-forth editing. This is a dialogue of iterative, collective development of your document, your project, and your abilities as a writer; not a corrective exercise. I prefer to use google doc because I think it has the best tools for co-writing. Tips and tricks Editing is the majority of writing . Editing is a craft you can hone. Here is a collection of tips and tricks for editing I\u2019ve collected over the years. Always consider your reader . Who are they? Why are they reading your document? How can you help them out? They will always thank you for making things clearer, more concise, and easier for them to follow. For each sentence, interrogate it: \"what is your purpose?\" It should contribute something specific to the document at hand, and that something should never be \u201ctell the reader you know this thing\u201d. Tell your reader only what they need to know in order to understand and care about what you\u2019re telling them, no more. Your job is not to convince your reader that you know stuff. Say it in a lot of words, then get rid of most of them . When you don\u2019t know how to say something concisely: don\u2019t worry about concision, write it out in as many words as possible, then edit them down. You\u2019ll often find that the reason you couldn\u2019t express your idea concisely is because it wasn\u2019t fully developed, and the act of writing \u2192 editing will help you develop the idea. Note: this is the vomit method on a small scale. Write in filler sentences . If you don't know how to say what you want to say, use a filler sentence that serves the same purpose, which you will edit/expand later. Separate out \"what is this sentence for\" from \"what are the words in this sentence\". Look out for referents . Words like \u201cthis\u201d, \u201cthat\u201d, et al. What do they refer to? Is it clear to the reader? Can they be replaced with something clearer, or more informative? The first draft, on the other hand, is dark magic voodoo shit . Where editing is a craft you can hone, writing from scratch is a different dumpster fire every time you put a pen to a blank page. Here are a few methods to get it out and move on with your life. The vomit method/shitty first draft . This can be summed up as: You need to write words. It's ok if they are garbage words. You can fix them later. TBH, all first drafts are shitty first drafts whose only purpose is to exist so you can move on to editing, and the vomit method is just one way to get it out of you as quickly as possible. The outline-first method . This sounds like elementary school stuff but it can really work. Collect the pieces you want/need to include in your document and arrange them in a bulleted list. Organize the overall structure of the document, identify missing pieces. The idea is to focus on pieces and structure not on language. Once you have the pieces in a structure you like, turn them into complete sentences and delete the bullet points. The San Antonio method. This is basically the vomit method with at least one coauthor and a whiteboard. TL;DR one person\u2019s job is to write on the board and everyone else\u2019s is to throw out ideas. The whiteboard author should take an attitude of \u201cyes, and\u201d, note down anything that\u2019s been said, and should try to prompt thinking about how they relate. Afterword, arrange your notes into an outline. Generative AI . I would not recommend using generative AI for your first draft, unless you\u2019re recombining words you\u2019ve already written. For example, if your fellowship asks for a community service statement, and you\u2019ve already written three of them for past applications but the prompt was slightly different and you\u2019ve done some new stuff since then. You can throw your old writing samples and updated CV and ask: \u201cI\u2019m writing a statement for a fellowship application. Here is the prompt and some previous statements I\u2019ve written. Please combine them to fit the prompt, preserving my writing voice and, ideally, the actual language I used, as much as possible\u201d. Once you have a collection of past submissions this will save a lot of time, but I would highly recommend against using GenAI to help with writing anything new - it tends to write many fluffy nice-sounding language without any real content, which is the exact opposite of what you want for subsequent editing, and it robs you of the idea-generation phase of writing which is arguably the most important part. Develop a regular writing practice Advice on specific pieces of academic writing (Links/advice to come) Writing an Abstract Structuring your paper Specific Aims: by the time your reader gets to your aims, they should be able to guess what they are without reading them. That is, you should have given them exactly and only the information they need to have a burning question, which your aims spell out a way of asking and answering. See Anatomy of a Specific Aims for more. Miscellaneous resources Mensh and Kording 2017 - Ten simple rules for structuring papers Carandini 2018 - How to write a paper (with me) The Perfect Sentence Vortex and How to Escape It","title":"Writing"},{"location":"Resources/writing/#writing","text":"Over the course of your time in the lab we will write a lot together. Manuscripts, fellowship/grant applications, conference abstracts\u2026 Writing is a craft, and scientific writing is a specific kind of writing. Writing effectively takes a lot of time and work. From the get go, I recommend everyone watch this lecture on how to write well . Watch it now, before you have to write anything. And watch it again in a year or two. Part of your training in the lab is to improve your writing skills, and IMO it\u2019s one of the most important parts. Remember: your three main outputs in the lab are figures, ideas, and code. Writing is a tool for developing your ideas, and it\u2019s the most tangible way you will communicate those ideas. Writing well will get you a job, and it will improve your science, because writing is a thinking tool as much as it\u2019s a communication tool (WARNING! these are not the same, see the lecture \ud83d\ude09). A heads up: when you get a draft back from me, it will likely have a lot of red ink. More red ink is good . Make sure to give yourself, and me, enough time to work on drafts together (e.g. I want to see abstract drafts a week before conference submission). For any document you submit, expect a lot of comments/suggestions and few rounds of back-and-forth editing. This is a dialogue of iterative, collective development of your document, your project, and your abilities as a writer; not a corrective exercise. I prefer to use google doc because I think it has the best tools for co-writing. Tips and tricks Editing is the majority of writing . Editing is a craft you can hone. Here is a collection of tips and tricks for editing I\u2019ve collected over the years. Always consider your reader . Who are they? Why are they reading your document? How can you help them out? They will always thank you for making things clearer, more concise, and easier for them to follow. For each sentence, interrogate it: \"what is your purpose?\" It should contribute something specific to the document at hand, and that something should never be \u201ctell the reader you know this thing\u201d. Tell your reader only what they need to know in order to understand and care about what you\u2019re telling them, no more. Your job is not to convince your reader that you know stuff. Say it in a lot of words, then get rid of most of them . When you don\u2019t know how to say something concisely: don\u2019t worry about concision, write it out in as many words as possible, then edit them down. You\u2019ll often find that the reason you couldn\u2019t express your idea concisely is because it wasn\u2019t fully developed, and the act of writing \u2192 editing will help you develop the idea. Note: this is the vomit method on a small scale. Write in filler sentences . If you don't know how to say what you want to say, use a filler sentence that serves the same purpose, which you will edit/expand later. Separate out \"what is this sentence for\" from \"what are the words in this sentence\". Look out for referents . Words like \u201cthis\u201d, \u201cthat\u201d, et al. What do they refer to? Is it clear to the reader? Can they be replaced with something clearer, or more informative? The first draft, on the other hand, is dark magic voodoo shit . Where editing is a craft you can hone, writing from scratch is a different dumpster fire every time you put a pen to a blank page. Here are a few methods to get it out and move on with your life. The vomit method/shitty first draft . This can be summed up as: You need to write words. It's ok if they are garbage words. You can fix them later. TBH, all first drafts are shitty first drafts whose only purpose is to exist so you can move on to editing, and the vomit method is just one way to get it out of you as quickly as possible. The outline-first method . This sounds like elementary school stuff but it can really work. Collect the pieces you want/need to include in your document and arrange them in a bulleted list. Organize the overall structure of the document, identify missing pieces. The idea is to focus on pieces and structure not on language. Once you have the pieces in a structure you like, turn them into complete sentences and delete the bullet points. The San Antonio method. This is basically the vomit method with at least one coauthor and a whiteboard. TL;DR one person\u2019s job is to write on the board and everyone else\u2019s is to throw out ideas. The whiteboard author should take an attitude of \u201cyes, and\u201d, note down anything that\u2019s been said, and should try to prompt thinking about how they relate. Afterword, arrange your notes into an outline. Generative AI . I would not recommend using generative AI for your first draft, unless you\u2019re recombining words you\u2019ve already written. For example, if your fellowship asks for a community service statement, and you\u2019ve already written three of them for past applications but the prompt was slightly different and you\u2019ve done some new stuff since then. You can throw your old writing samples and updated CV and ask: \u201cI\u2019m writing a statement for a fellowship application. Here is the prompt and some previous statements I\u2019ve written. Please combine them to fit the prompt, preserving my writing voice and, ideally, the actual language I used, as much as possible\u201d. Once you have a collection of past submissions this will save a lot of time, but I would highly recommend against using GenAI to help with writing anything new - it tends to write many fluffy nice-sounding language without any real content, which is the exact opposite of what you want for subsequent editing, and it robs you of the idea-generation phase of writing which is arguably the most important part. Develop a regular writing practice Advice on specific pieces of academic writing (Links/advice to come) Writing an Abstract Structuring your paper Specific Aims: by the time your reader gets to your aims, they should be able to guess what they are without reading them. That is, you should have given them exactly and only the information they need to have a burning question, which your aims spell out a way of asking and answering. See Anatomy of a Specific Aims for more.","title":"Writing"},{"location":"Resources/writing/#miscellaneous-resources","text":"Mensh and Kording 2017 - Ten simple rules for structuring papers Carandini 2018 - How to write a paper (with me) The Perfect Sentence Vortex and How to Escape It","title":"Miscellaneous resources"}]}