{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Lab-Handbook The lab handbook of the Levenstein Lab for NeuroAI and Dynamics at Yale University. Please note that this is an in-development and \"living document\", which means that it will evolve as needed to fit the lab as it grows and develops. Furthermore, it means that as a lab member, you're encouraged to contribute and discuss its contents with Dan and in the #lab-handbook channel on slack. About the lab Like learning, sleep changes the brain to improve its future performance. Unlike learning, these changes occur in the absence of overt behavior or sensory input, and rely solely on neural activity that is spontaneously generated by the brain itself. This \u201coffline learning\u201d thus contains a mystery: how does spontaneous activity improve brain function? Our lab aims to develop theories of offline learning that shed light on this mystery, and can be used to mimic its computational benefits in artificial neural networks or understand its disruption in neuropsychiatric disorders. Our work generally focuses on spatial representation in the hippocampal formation, and a phenomenon called sharp wave ripples - high frequency oscillations in the hippocampus that coordinate activity across the brain and simulate wake-like \u201creplay\u201d trajectories during sleep. We use artificial neural networks (ANNs), dynamical systems theory, and neural data analysis to study how these internally-generated dynamics support offline learning \u2013 working closely with experimental collaborators to inspire the design of computational models and to compare them in experimental data. This NeuroAI approach, in which brain-inspired ANNs are built and used as models for the brain, is particularly well-suited to bridge neurons\u2019 circuit and cellular-level properties with their computational capacities, and allows us to study three questions central to our research: \u201c How does spontaneous activity emerge and self-organize in neural networks? \u201d \u201c How does plasticity during spontaneous activity change the brain? \u201d \u201c How do those changes improve the brain\u2019s operations and performance on future tasks? \u201d In addition to our work on sleep, the lab works broadly at the interface of theoretical and experimental neuroscience - applying computational methods to a variety of interesting problems involving neural dynamics and computation with experimentalist collaborators. Where to start? So you want to join the lab? - prospective members start here Onboarding - new members start here","title":"Lab-Handbook"},{"location":"#lab-handbook","text":"The lab handbook of the Levenstein Lab for NeuroAI and Dynamics at Yale University. Please note that this is an in-development and \"living document\", which means that it will evolve as needed to fit the lab as it grows and develops. Furthermore, it means that as a lab member, you're encouraged to contribute and discuss its contents with Dan and in the #lab-handbook channel on slack. About the lab Like learning, sleep changes the brain to improve its future performance. Unlike learning, these changes occur in the absence of overt behavior or sensory input, and rely solely on neural activity that is spontaneously generated by the brain itself. This \u201coffline learning\u201d thus contains a mystery: how does spontaneous activity improve brain function? Our lab aims to develop theories of offline learning that shed light on this mystery, and can be used to mimic its computational benefits in artificial neural networks or understand its disruption in neuropsychiatric disorders. Our work generally focuses on spatial representation in the hippocampal formation, and a phenomenon called sharp wave ripples - high frequency oscillations in the hippocampus that coordinate activity across the brain and simulate wake-like \u201creplay\u201d trajectories during sleep. We use artificial neural networks (ANNs), dynamical systems theory, and neural data analysis to study how these internally-generated dynamics support offline learning \u2013 working closely with experimental collaborators to inspire the design of computational models and to compare them in experimental data. This NeuroAI approach, in which brain-inspired ANNs are built and used as models for the brain, is particularly well-suited to bridge neurons\u2019 circuit and cellular-level properties with their computational capacities, and allows us to study three questions central to our research: \u201c How does spontaneous activity emerge and self-organize in neural networks? \u201d \u201c How does plasticity during spontaneous activity change the brain? \u201d \u201c How do those changes improve the brain\u2019s operations and performance on future tasks? \u201d In addition to our work on sleep, the lab works broadly at the interface of theoretical and experimental neuroscience - applying computational methods to a variety of interesting problems involving neural dynamics and computation with experimentalist collaborators. Where to start? So you want to join the lab? - prospective members start here Onboarding - new members start here","title":"Lab-Handbook"},{"location":"contact/","text":"Lab Information Wu Tsai Institute, Center for Neurocomputation and Machine Intelligence 100 College Street, New Haven, CT 06511 Lab Members Name Role Email Daniel Levenstein Primary Investigator daniel.levenstein@yale.edu Andrea Cumpelik Postdoctoral Researcher andrea.cumpelik@yale.edu Viggy Vanchinathan Postgraduate Associate vignesh.vanchinathan@yale.edu Huihong Li Masters Student huihong.li@yale.edu Aidan Schneider Postdoctoral Researcher aidan.schneider@yale.edu","title":"Contact"},{"location":"onboarding/","text":"This page delineates the onboarding processes. Please try to follow it step by step. If/when you find steps that are out of date, that are poorly described, or that you think should be added to the process, please update the Lab Handbook. You should have made at least one change by the time you complete onboarding (if you don\u2019t know how to do that, you\u2019ll learn!), and please follow this practice whenever using the lab handbook. Important Emails to Look For Appointment Confirmation, from AutomationManager@brassring.com Outlines position, job responsibilities, compensation, funding sources, term length. Welcome E-mail, from Jennifer Coughlin Access to NetID, your Yale email, and Workday for trainings/benefits New to Yale? Get Yale NetID/email (note: this will take about 24 hours) Your NetID is a unique identifier for you in the system, and can also be used to log into the private YaleSecure WiFi network. Emails typically follow first.last@yale.edu ; you may need to wait for 20 minutes or more after your netID activation to access your email. Set up multifactor authentication (MFA) Usually done through Duo, which you will need to accesss your email. Get Yale ID card Multiple offices are available to get an ID card printed. Note the hours! Yale Central ID Center, 57 Lock St ( M-F, 8am-4pm ), walk-in visits accepted but appointments are encouraged. Medical School ID Center, 333 Cedar St ( M-Th, 8am-12pm ) for walk-ins Get 100 College/WTI card access (note: it will take about 24 hours for your card to gain access) Note that a Yale ID card does NOT automatically provide access to 100 College/WTI. You must request access seaparately; ideally email the WTI facilities manager, Matt Milano . Familiarize yourself with campus, and how to get to 100 College Institute Multiple areas of campus (Old Campus, Science Hill, etc) The Wu Tsai Institute is located on the 11th floor at 100 College Street. The building is owned by Alexion Pharmaceuticals (owned by AstraZeneca) We are located in the Center for Neurocomputation and Machine Intelligence, to the right side if you are facing towards the \"Yale Wu Tsai Institute\" sign. Sign up for an orientation. These are available for both Postdocs and Postgrads. Workday stuff Complete your I-9 . It is a federal requirement that the I-9 form is submitted by three business days of your start date. Bring the right documents ! The main office where you can get an appointment is 221 Whitney Avenue Sign up for Health insurance and please see the lab handbook section on health, wellness, and work-life balance Complete the required training courses with Workday Learning Trainings may take multiple hours, and you may want to do this over multiple days. Your first day Join the lab slack Familiarize yourself with Lab policies, practices, and expectations. You don\u2019t need to read the whole thing, but do read over the expectations for your position in the lab and working hours, remote working, and vacation Send Viggy a preferred email for the shared lab Google Calendar. You'll receive read & write access to see & add events. We also have an slack integration set up to send reminders for upcoming events. Schedule your regular 1-on-1 meeting with Dan. Send Dan your headshot and bio for the lab website. Join Levenstein Lab github organization - send Dan your github username and he'll add you Basic Github tutorial - make your github account, learn to make a PR. Follow the lab handbook repository so you get notified of future updates to the handbook, and have the opportunity to read and discuss them Your first PR: Update the lab handbook to improve something that was unclear or missing up until now. Add your contact information to contact.md Join Mailing lists/groups at Yale First readings (first week) : Discuss with Dan your interests and potential first projects. In addition to any reading he suggests, take a look at Recommended Reading . If you\u2019re new to working with neural networks, or to neuroAI, I highly recommend these as places to start: Artificial Neural Networks for Neuroscientists: A Primer A deep learning framework for neuroscience The neuroconnectionist research programme Getting started (1-2 Weeks) : Read about the Lab Code and Software Practices , and the introduction of the good research code handbook . We don\u2019t follow this religiously, but it\u2019s a good place to start. Something to remember: the main outputs of your work in the lab will be ideas , figures , and code . Of those, your code is unique - it's your primary research tool and its the best way for other people (including your future self) to be able reproduce and build on your work. Thus, it behooves you to invest some energy in writing good code. If you don't have a preferred IDE, Get VS Code and do the VS code tutorial Follow either the ANN path or the data analysis path below ANNs path Your first project: PyTorch Tutorials (https://docs.pytorch.org/tutorials/, https://docs.pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) Set up a project repository in which you'll do the tutorial - THIS IS THE MOST IMPORTANT STEP. Setting up a project repository, with its own environment and specified dependencies, will save you infinite headaches in the future. Get in the practice now. By the end of this, you should have trained a multi-layer perceptron (MLP) to solve fMNIST Next, modify the network in some way you find interesting. Get set up on the misha compute cluster and learn how to use it . Your second project: pRNN Tutorials By the end of this, you should have trained a basic predictive RNN in a gridworld environment, and analyzed its spatial tuning properties Next, modify or use the pRNN network in some way you find interesting. This could involve a new environment or behavioral policy, or changes to the network architecture, loss, or learning rule. Feel free to discuss some ideas with Dan. Data analysis path : Your first project: discuss with Dan the data you'd like to work with and choose your own adventure ;)... this path is still under construction. Consider working with pynapple , which is a good package for working with neural timeseries data and has some tutorials.","title":"Onboarding"},{"location":"Policies/code_software/","text":"Code and software practices Maintaining good code is essential to the efficient functioning of the lab. Best software practices mandate that the code is well-documented, commented, and modular. As code may be shared within our lab (and outside), these guidlines ensure that the code is understandable and usable quickly. There are plenty of great resources online regarding how to follow these practices. Good Research Code Handbook Here's how we may format our code as a lab: Repository Types Project (\u201cLab Notebook\u201d): A repository for managing the day-to-day progress of a research project \u2014 analyses in progress, exploratory modeling, notes, and experiment logs. The cookie cutter repository (as described in the good research code handbook) is a good place to start, which will get you started with a file structure and environment. Each project should have its own repository. Package : In the course of a project, you\u2019ll likely develop something reusable \u2014 e.g., a model, simulation tool, or analysis pipeline. A package is a cleaned-up, documented, and versioned version of that tool, designed so others (future lab members and the broader community) can easily use and extend it. This repository should be jointly owned by you and the lab organization (e.g., under the lab\u2019s GitHub org). As your project moves from an exploration to an exploitation phase, work with Viggy to create and maintain a package repository. Publication : A repository for reproducing all figures and analyses in a specific paper. This repository is owned by the lab organization (since publications represent lab outputs). As you prepare to submit a manuscript, work with Viggy to set up this repository. The paper repository should depend on the relevant package (don\u2019t reimplement analysis code) and should pin specific package versions (e.g., via requirements.txt, pyproject.toml, or git submodules) to ensure reproducibility. Include figure-generation scripts, processed data, and notebooks. Conventions Patrick Mineault's code handbook above is a must-read before you start coding. It reviews the best ways to set up your project, to maintain clarity and cleanliness, to test your code, and to document your code as well. The handbook is the best way to learn these conventions, especially when it comes to efficiency and testing, which rely on great examples. However a few helpful tips to get you started in the right direction Use git often, often more than you think you should. See Resources and How-Tos/basic_github.md for additional information. Setup your repository correctly, from the beginning. Mineault's base directory structure works really well to keep the inputs and outputs of your code separate: data folder: raw input data docs folder: documentation, kept separate for later publishing results folder: code outputs, figures, tables, CSVs scripts folder: scripts for analysis like .ipynb notebooks srcs folder: reusable code that works at the base of all the scripts tests folder: unit tests This can be downloaded with the true-neutral-cookiecutter . Maintain your environments. Packages you import may have dependences on other packages with specific versions, or perhaps even specific versions of python. Installing all packages into one environment will make it extremely difficult to move the code to another computer or user (i.e. it's less portable ). We can use conda as a package manager and virtual environment manager for this. conda can be installed via miniconda , which is a lighter-weight version of the original Anaconda Distribution of packages/python. This will allow you to use conda to make virtual environments and manage packages. Use a .yml file. These are special files that specify instructions on which packages comprise an environment. A different researcher using your code can automatically recreate your environment exactly as you have it by using this file, ensuring proper portability. Maintain good style. This includes commenting, which should be done at the top of functions, classes, modules, files, etc. This helps both you and others understand code. Pythonic code can be confusing sometimes; you'll need to make the tradeoff between clarity and brevity. Download a linter (e.g. Ruff) to help you format your code. VS Code VS Code is a great IDE because it's open source (unlike e.g. PyCharm), highly customizable via extensions, and has great remote development support (which is important when working with the cluster). You can download it here . If you are unfamiliar with VS Code/IDEs in general, see the VS Code tutorial for more info on how to get started.","title":"Good Software"},{"location":"Policies/code_software/#code-and-software-practices","text":"Maintaining good code is essential to the efficient functioning of the lab. Best software practices mandate that the code is well-documented, commented, and modular. As code may be shared within our lab (and outside), these guidlines ensure that the code is understandable and usable quickly. There are plenty of great resources online regarding how to follow these practices. Good Research Code Handbook Here's how we may format our code as a lab:","title":"Code and software practices"},{"location":"Policies/code_software/#repository-types","text":"Project (\u201cLab Notebook\u201d): A repository for managing the day-to-day progress of a research project \u2014 analyses in progress, exploratory modeling, notes, and experiment logs. The cookie cutter repository (as described in the good research code handbook) is a good place to start, which will get you started with a file structure and environment. Each project should have its own repository. Package : In the course of a project, you\u2019ll likely develop something reusable \u2014 e.g., a model, simulation tool, or analysis pipeline. A package is a cleaned-up, documented, and versioned version of that tool, designed so others (future lab members and the broader community) can easily use and extend it. This repository should be jointly owned by you and the lab organization (e.g., under the lab\u2019s GitHub org). As your project moves from an exploration to an exploitation phase, work with Viggy to create and maintain a package repository. Publication : A repository for reproducing all figures and analyses in a specific paper. This repository is owned by the lab organization (since publications represent lab outputs). As you prepare to submit a manuscript, work with Viggy to set up this repository. The paper repository should depend on the relevant package (don\u2019t reimplement analysis code) and should pin specific package versions (e.g., via requirements.txt, pyproject.toml, or git submodules) to ensure reproducibility. Include figure-generation scripts, processed data, and notebooks.","title":"Repository Types"},{"location":"Policies/code_software/#conventions","text":"Patrick Mineault's code handbook above is a must-read before you start coding. It reviews the best ways to set up your project, to maintain clarity and cleanliness, to test your code, and to document your code as well. The handbook is the best way to learn these conventions, especially when it comes to efficiency and testing, which rely on great examples. However a few helpful tips to get you started in the right direction Use git often, often more than you think you should. See Resources and How-Tos/basic_github.md for additional information. Setup your repository correctly, from the beginning. Mineault's base directory structure works really well to keep the inputs and outputs of your code separate: data folder: raw input data docs folder: documentation, kept separate for later publishing results folder: code outputs, figures, tables, CSVs scripts folder: scripts for analysis like .ipynb notebooks srcs folder: reusable code that works at the base of all the scripts tests folder: unit tests This can be downloaded with the true-neutral-cookiecutter . Maintain your environments. Packages you import may have dependences on other packages with specific versions, or perhaps even specific versions of python. Installing all packages into one environment will make it extremely difficult to move the code to another computer or user (i.e. it's less portable ). We can use conda as a package manager and virtual environment manager for this. conda can be installed via miniconda , which is a lighter-weight version of the original Anaconda Distribution of packages/python. This will allow you to use conda to make virtual environments and manage packages. Use a .yml file. These are special files that specify instructions on which packages comprise an environment. A different researcher using your code can automatically recreate your environment exactly as you have it by using this file, ensuring proper portability. Maintain good style. This includes commenting, which should be done at the top of functions, classes, modules, files, etc. This helps both you and others understand code. Pythonic code can be confusing sometimes; you'll need to make the tradeoff between clarity and brevity. Download a linter (e.g. Ruff) to help you format your code.","title":"Conventions"},{"location":"Policies/code_software/#vs-code","text":"VS Code is a great IDE because it's open source (unlike e.g. PyCharm), highly customizable via extensions, and has great remote development support (which is important when working with the cluster). You can download it here . If you are unfamiliar with VS Code/IDEs in general, see the VS Code tutorial for more info on how to get started.","title":"VS Code"},{"location":"Policies/conferences_workshops/","text":"Conferences You are encouraged to submit your work to conferences. If you are presenting your work, the lab will fund your registration and travel and any other conference-related expenses. Meals can be reimbursed via saving all your receipts, or through a per diem (I\u2019d recommend the per diem). Please try to keep these costs down (e.g. with flight and hotel selection, and booking early). Please also keep your eyes out and apply for any travel awards. Your CV and the lab\u2019s wallet will thank you. Like with other fellowship opportunities, I'll also forward travel award opportunities to the lab when I see them. Please plan to send me a draft of your abstract one week before deadline . This gives us enough time for a few rounds of edits and discussion, and to develop the story together. Your work, and your abstract acceptance rate, will thank you. I\u2019ll note that you often feel like your project is not-quite-ready when you start writing your abstract, and that the abstract writing process is often when the project gets developed to the point where it\u2019s ready to submit\u2026 long story short, don\u2019t be afraid to write an abstract even if you feel you\u2019re not ready :) As with a paper submission, nothing goes out without all co-authors seeing and approving the final version. The exact number of conferences you should expect to present at per year will depend on your career stage, and status of your project. IMO the best times to present are when you're halfway through a project, and trying to figure out what the story is, and just after you've posted a preprint. See Resources - Travel for information on booking travel.","title":"Conferences and Workshops"},{"location":"Policies/conferences_workshops/#conferences","text":"You are encouraged to submit your work to conferences. If you are presenting your work, the lab will fund your registration and travel and any other conference-related expenses. Meals can be reimbursed via saving all your receipts, or through a per diem (I\u2019d recommend the per diem). Please try to keep these costs down (e.g. with flight and hotel selection, and booking early). Please also keep your eyes out and apply for any travel awards. Your CV and the lab\u2019s wallet will thank you. Like with other fellowship opportunities, I'll also forward travel award opportunities to the lab when I see them. Please plan to send me a draft of your abstract one week before deadline . This gives us enough time for a few rounds of edits and discussion, and to develop the story together. Your work, and your abstract acceptance rate, will thank you. I\u2019ll note that you often feel like your project is not-quite-ready when you start writing your abstract, and that the abstract writing process is often when the project gets developed to the point where it\u2019s ready to submit\u2026 long story short, don\u2019t be afraid to write an abstract even if you feel you\u2019re not ready :) As with a paper submission, nothing goes out without all co-authors seeing and approving the final version. The exact number of conferences you should expect to present at per year will depend on your career stage, and status of your project. IMO the best times to present are when you're halfway through a project, and trying to figure out what the story is, and just after you've posted a preprint. See Resources - Travel for information on booking travel.","title":"Conferences"},{"location":"Policies/health_wellness/","text":"Health, wellness, and work-life balance More to come. See also mental health resources","title":"Health & Wellness"},{"location":"Policies/health_wellness/#health-wellness-and-work-life-balance","text":"More to come. See also mental health resources","title":"Health, wellness, and work-life balance"},{"location":"Policies/hours_remote_vacation/","text":"Working hours, remote work, and vacation As our work is predominantly theoretical/computational, we have a lot of flexibility around when and where we work. Please set your hours based on how you work best. That being said, part of our job is being a contributing member to the lab community, and in my experience the spontaneous interactions we have here are some of the most impactful for the quality of our research. I'm generally in lab ~930-~6, and I try to be as available as possible during that time. If it fits you, I would encourage you to plan one day a week where you work from home (or elsewhere out of office). This shift in perspective can be helpful for your work and I encourage you to take advantage of this time to think freely and critically about your project and current approaches. I do ask that you plan to attend lab meetings in person -- in my experience, remote attendance encourages people to listen (at best), rather than participate, in lab meetings. Also, I ask that you plan to be physically in lab 3-4 days a week. Of course, this can vary week to week and exceptions will be made to fit people\u2019s circumstances. I expect you will be taking vacations. I usually take off from the weekend before Christmas until the weekend after new years, a few days around thanksgiving, a week or two over the summer, and the various official 3-day weekends. I\u2019ll lightly respond to emails during these times, do some reading, maybe some writing. But in general I like to use this time to recharge, spend some time with family and hobbies, and I encourage you all to do the same. For more about work-life balance in academia, please see [Work-life balance] TODO: @dan include link .","title":"Hours & Remote Work"},{"location":"Policies/hours_remote_vacation/#working-hours-remote-work-and-vacation","text":"As our work is predominantly theoretical/computational, we have a lot of flexibility around when and where we work. Please set your hours based on how you work best. That being said, part of our job is being a contributing member to the lab community, and in my experience the spontaneous interactions we have here are some of the most impactful for the quality of our research. I'm generally in lab ~930-~6, and I try to be as available as possible during that time. If it fits you, I would encourage you to plan one day a week where you work from home (or elsewhere out of office). This shift in perspective can be helpful for your work and I encourage you to take advantage of this time to think freely and critically about your project and current approaches. I do ask that you plan to attend lab meetings in person -- in my experience, remote attendance encourages people to listen (at best), rather than participate, in lab meetings. Also, I ask that you plan to be physically in lab 3-4 days a week. Of course, this can vary week to week and exceptions will be made to fit people\u2019s circumstances. I expect you will be taking vacations. I usually take off from the weekend before Christmas until the weekend after new years, a few days around thanksgiving, a week or two over the summer, and the various official 3-day weekends. I\u2019ll lightly respond to emails during these times, do some reading, maybe some writing. But in general I like to use this time to recharge, spend some time with family and hobbies, and I encourage you all to do the same. For more about work-life balance in academia, please see [Work-life balance] TODO: @dan include link .","title":"Working hours, remote work, and vacation"},{"location":"Policies/meetings/","text":"1-on-1 Meetings All lab members should have a regularly scheduled 1-on-1 meeting with me. This can be weekly or bi-weekly, and will often be used to discuss results and next steps in your project. One strategy that worked well for me during my PhD and postdoc was to come to 1-on-1 meetings with slides. These would include: agenda outline - what do you want to talk about this week quick recap of the current goals, approach, and TL;DR previous meeting figures showing the results from the week ideas for what you think your next steps should be While I generally encourage you to figure out what works best for you, and won\u2019t make this a requirement, I am putting it here as a suggested practice that benefits both of us. It helps me more effectively advise you and where you\u2019re at in your project, and it helps you to make these slides - it makes you go the extra step to generate semi-presentable figures of your results, it prompts you to think of where you\u2019re at and where you should go next, and you'll have many slides to start from when you have to present your work (e.g. in lab meeting). Over time, you become quite good at quickly putting together and presenting effective slide presentations. Of course, we\u2019re not always able to have new results for each meeting - sometimes we\u2019ve been productive, but just thinking; sometimes life has happened and we haven\u2019t made any progress on our projects. That\u2019s ok, and I\u2019m always happy to chat about anything, either why you think things aren\u2019t working, some ideas you've been thinking about, or just generally how things are going. Regardless, it\u2019s good to have the meeting on the calendar and we can always skip a week or have a quick check in if there\u2019s not much to discuss. However, I would encourage you to not get in the habit of pushing back meetings, as a common failure mode of a PhD is a spiral in which you avoid meeting with your advisor because you don\u2019t have results, putting pressure on yourself to have more results for the next meeting, which you then avoid because you don\u2019t have \u201cgood enough\u201d results, \u2026 you see where this goes. This meeting can also be used to discuss career plans, etc. From my point of view, your scheduled 1-on-1 meeting is time set aside in my calendar for you, your research, and your career, and is there for you to use however you think would be most helpful. Please note that 1-on-1 meetings are not the only time I have for you. I am always happy to discuss results: positive or negative, challenges you\u2019re facing, or anything else you want to talk about related to your project, career, or science in general. You can always message me on slack, and if my door is open, please come in! Journal Club Journal clubs and lab buisness meetings are every Thursday, at 10AM. Format: We follow a rotation picking a paper to read. Paper should be sent to the group 1 week before the journal club (i.e. EOD the previous Thursday). There will usually be many interesting papers to pick from in the #papers channel on slack. Each lab member is assigned a figure or two to walk the group through. (This approach makes sure we all read the paper, and avoids the trap of one person reading and presenting while others do not engage.) You should come prepared to explain your assigned figure (no slides needed), answer questions about it, and ask the group about anything you did not understand. If there are supplemental figures or methods associated with your figure, you should be familiar with those as well. It's OK to not understand everything fully - the point of journal club is to talk through and learn together.","title":"Meetings"},{"location":"Policies/meetings/#1-on-1-meetings","text":"All lab members should have a regularly scheduled 1-on-1 meeting with me. This can be weekly or bi-weekly, and will often be used to discuss results and next steps in your project. One strategy that worked well for me during my PhD and postdoc was to come to 1-on-1 meetings with slides. These would include: agenda outline - what do you want to talk about this week quick recap of the current goals, approach, and TL;DR previous meeting figures showing the results from the week ideas for what you think your next steps should be While I generally encourage you to figure out what works best for you, and won\u2019t make this a requirement, I am putting it here as a suggested practice that benefits both of us. It helps me more effectively advise you and where you\u2019re at in your project, and it helps you to make these slides - it makes you go the extra step to generate semi-presentable figures of your results, it prompts you to think of where you\u2019re at and where you should go next, and you'll have many slides to start from when you have to present your work (e.g. in lab meeting). Over time, you become quite good at quickly putting together and presenting effective slide presentations. Of course, we\u2019re not always able to have new results for each meeting - sometimes we\u2019ve been productive, but just thinking; sometimes life has happened and we haven\u2019t made any progress on our projects. That\u2019s ok, and I\u2019m always happy to chat about anything, either why you think things aren\u2019t working, some ideas you've been thinking about, or just generally how things are going. Regardless, it\u2019s good to have the meeting on the calendar and we can always skip a week or have a quick check in if there\u2019s not much to discuss. However, I would encourage you to not get in the habit of pushing back meetings, as a common failure mode of a PhD is a spiral in which you avoid meeting with your advisor because you don\u2019t have results, putting pressure on yourself to have more results for the next meeting, which you then avoid because you don\u2019t have \u201cgood enough\u201d results, \u2026 you see where this goes. This meeting can also be used to discuss career plans, etc. From my point of view, your scheduled 1-on-1 meeting is time set aside in my calendar for you, your research, and your career, and is there for you to use however you think would be most helpful. Please note that 1-on-1 meetings are not the only time I have for you. I am always happy to discuss results: positive or negative, challenges you\u2019re facing, or anything else you want to talk about related to your project, career, or science in general. You can always message me on slack, and if my door is open, please come in!","title":"1-on-1 Meetings"},{"location":"Policies/meetings/#journal-club","text":"Journal clubs and lab buisness meetings are every Thursday, at 10AM. Format: We follow a rotation picking a paper to read. Paper should be sent to the group 1 week before the journal club (i.e. EOD the previous Thursday). There will usually be many interesting papers to pick from in the #papers channel on slack. Each lab member is assigned a figure or two to walk the group through. (This approach makes sure we all read the paper, and avoids the trap of one person reading and presenting while others do not engage.) You should come prepared to explain your assigned figure (no slides needed), answer questions about it, and ask the group about anything you did not understand. If there are supplemental figures or methods associated with your figure, you should be familiar with those as well. It's OK to not understand everything fully - the point of journal club is to talk through and learn together.","title":"Journal Club"},{"location":"Resources/adobe/","text":"We typically use Adobe Illustrator and Photoshop to make scientific figures. To get an Adobe license, you will need to submit a request for Adobe Creative Cloud to IT; see this FAQ section . Licenses run within a fixed period, from August to August, regardless of when you register for one. Students at the Yale School of Medicine receive Adobe CC for free, and students from other departments should request it through their school directly. Other staff (like postdocs, postgrads, technicians, etc.) at YSM can request an upgrade using this form . The $15/year charge listed will be covered by the department. For non YSM-staff, Yale provides the license to staff via Software Library . IT will want you to provide justification for the upgrade; explaining that you need Illustrator/Photoshop to edit scientific figures for posters or publications should be sufficient.","title":"Adobe"},{"location":"Resources/basic_github/","text":"Working on code collaboratively can be a challenge. Managing multiple versions with different functionality can be especially difficult. Version control software allows us to manage collaborative software development by keeping track of different versions and who contributed to what. We will use Git, the most popular framework for version control, and GitHub, a site used to host and manage remote copies of your software. It's important that you become familiar with how to use Git, as it will allow you to collaborate with your colleagues and contribute to meaningful analysis. You should be familiar with: Repositories the add , commit , push commands the status command the difference between branches and forks pull requests and issues how Github integrates with repositories and the command line Here are some basic tutorials you may want to follow: GitHub Hello World tutorial (highly recommended; concise but also text-heavy) GitHub Desktop Tutorial helpful to get started with a graphical user interface (GUI) rather than command line, if you're more comfortable with that. There is also a graphical interface on VSCode. Learn Git Branching (JS Applet) (optional; interactive and visual but perhaps too deep) This Lab-Handbook allows you to make your own changes and push them to be integrated into the content. To do this, clone the repository to your local machine, make your changes, then add, commit and push: git clone https://github.com/LevensteinLab/Lab-Handbook.git git checkout -b BRANCH_NAME (this creates a new branch called BRANCH_NAME and switches to it) Make changes git add . (the dot is code for \"everything in this folder\") git commit -m MESSAGE (replace the message with a one-sentence description of what you changed) git push origin BRANCH_NAME Navigate to the Lab-Handbook GitHub repository You may see a yellow notification bar that indicates your branch is \"ahead\" of the main repository. Submit a pull request to integrate the changes into the final repository Dan will approve it","title":"Basic Github"},{"location":"Resources/booking/","text":"Booking Rooms at 100 College St It's possible to book the conference rooms on our floor for meetings. This is done through Robin . All you need to do is sign in with your Yale Account. There are two ways to book rooms. On the Schedule tab: You can see upcoming public meetings and your meetings on the My Meetings tab. Book rooms by looking at the schedule format (like a Gantt chart), and hovering over the room and time you want. On the Office tab: You can see a layout of the floor, as well as what rooms are available. Book rooms by clicking on a room and viewing available times. Input required details and submit.","title":"Booking Rooms"},{"location":"Resources/booking/#booking-rooms-at-100-college-st","text":"It's possible to book the conference rooms on our floor for meetings. This is done through Robin . All you need to do is sign in with your Yale Account. There are two ways to book rooms. On the Schedule tab: You can see upcoming public meetings and your meetings on the My Meetings tab. Book rooms by looking at the schedule format (like a Gantt chart), and hovering over the room and time you want. On the Office tab: You can see a layout of the floor, as well as what rooms are available. Book rooms by clicking on a room and viewing available times. Input required details and submit.","title":"Booking Rooms at 100 College St"},{"location":"Resources/gen_ai/","text":"Generative AI Use There has been immense progress in the last 2-3 years regarding the use of language models to assist in writing, learning, and code generation. With this assistance comes a responsibility to use it responsibly and ethically. Below are some compiled resources on how to do. The key points are to take ownership of ideas, code, and analysis generated by LLMs and double check your work by cross-referencing with other sources. Use it transparently and provide proper attribution. LLMs still exhibit phenomena such as sycophancy and hallucination, which may alter the reliability of its generated answers. Resources Living guidelines on the responsible use of generative AI in research (European Commission) Reminder of the Importance of Research Integrity & Use of AI (University of Virginia) Effective and Responsible Use of AI in research (University of Washington, Georgia Tech) Slide from Patrick Mineault on potential pros of AI use (Dan on Bluesky) Should neuroscientists 'vibe code'?(Benjamin Dichter, The Transmitter) GitHub Copilot Access As university-affiliated researchers, we may have access to AI completion tools such as GitHub Copilot. The Pro tier provides a 30-day free trial for researchers/educators. Here are the steps to get access: Visit the GitHub documentation on Copilot Pro access. Click on \"Apply to GitHub Education as a teacher\". Navigate to Education Benefits settings Complete the form and submit. You may need to verify that you have an @yale.edu email address and provide a picture of your ID card. The application will be approved by GitHub admins. You should see a coupon for GitHub Copilot Pro populate in 48-72 hours. This provides access for 30 days. This can get renewed.","title":"GenAI"},{"location":"Resources/gen_ai/#generative-ai-use","text":"There has been immense progress in the last 2-3 years regarding the use of language models to assist in writing, learning, and code generation. With this assistance comes a responsibility to use it responsibly and ethically. Below are some compiled resources on how to do. The key points are to take ownership of ideas, code, and analysis generated by LLMs and double check your work by cross-referencing with other sources. Use it transparently and provide proper attribution. LLMs still exhibit phenomena such as sycophancy and hallucination, which may alter the reliability of its generated answers.","title":"Generative AI Use"},{"location":"Resources/gen_ai/#resources","text":"Living guidelines on the responsible use of generative AI in research (European Commission) Reminder of the Importance of Research Integrity & Use of AI (University of Virginia) Effective and Responsible Use of AI in research (University of Washington, Georgia Tech) Slide from Patrick Mineault on potential pros of AI use (Dan on Bluesky) Should neuroscientists 'vibe code'?(Benjamin Dichter, The Transmitter)","title":"Resources"},{"location":"Resources/gen_ai/#github-copilot-access","text":"As university-affiliated researchers, we may have access to AI completion tools such as GitHub Copilot. The Pro tier provides a 30-day free trial for researchers/educators. Here are the steps to get access: Visit the GitHub documentation on Copilot Pro access. Click on \"Apply to GitHub Education as a teacher\". Navigate to Education Benefits settings Complete the form and submit. You may need to verify that you have an @yale.edu email address and provide a picture of your ID card. The application will be approved by GitHub admins. You should see a coupon for GitHub Copilot Pro populate in 48-72 hours. This provides access for 30 days. This can get renewed.","title":"GitHub Copilot Access"},{"location":"Resources/hpc/","text":"Getting access to the Misha HPC As part of computational research, we will need to dispatch jobs to high-performance computing (HPC) clusters. Access to these clusters gives us stronger power for computationally-intensive tasks like training models. Running the same process on your local machine may take much more time. To get started visit this page for some info about the HPC prepared by the Yale Center for Research Computing (YCRC) specifically for the Wu Tsai Institute. To use the cluster off-campus, you will need to use a VPN, please see the vpn.md file for instructions. Instructions Fill out the form to access the cluster, noting Dan as the PI from which to get access. You should get access in ~48 hours. Receive email from hpc@yale.edu with your username and instructions on how to login. Choose login method. Access to Misha needs to be done through Secure Shell (SSH). Other clusters have a web interface for logging on (Bouchet, Grace, McCleary, and Milgram). Find the links for the platform, called Open OnDemand (OOD), here . ( First time login only ) Generate your public and private ssh keys. These keys are used to authenticate you during the remote login (i.e. they tell the cluster that you're you.). Keep the private key a secret! Instructions on how to do this can be found here . Note: the example in the documentation uses the RSA encryption scheme, but using the ssh-keygen command on Macs without any additional argument will use the Ed25519 encryption scheme. The key still works and will be stored in something like id_ed25519.pub . Sidebar from Viggy: If you're interested in math, I'd highly recommend reading up on RSA. The RSA public/private key method works beause it's easy to multiply two large prime numbers together, but extremely hard to factor that product back into those primes! ( First time login only ) Upload your public key to the SSH Key Uploader . This allows the cluster to associate it with your netID, which you use to sign in. Login to the cluster. Use the Terminal: Type ssh YOUR_NET_ID@misha.ycrc.yale.edu . It will prompt you for your passcode. After you provide it, it will ask you choose a second authentication option. Type 1 to authenticate via a DUO push notification. Use your IDE: Open VSCode, and click the blue button in the bottom left corner of the screen. It looks like two chevron arrows pointing to each other. Click SSH, and Add New SSH Host Type ssh YOUR_NET_ID@misha.ycrc.yale.edu If it asks you for a config file, select the one with the .ssh/ path (often the first option). This tells VSCode where to look for your private key (which is still protected by your passcode). Enter your passcode when prompted. Type 1 to send a DUO push notification, and accept it. Submit jobs! Type exit to close the connection. About the HPC Consists of multiple groups of computers called nodes . Login node is shared between all users; handles all user logins and is usually excluded from running actual code jobs Compute nodes which are the majority of all the computers in the HPC; where the tasks are performed Can run both interactive and batch jobs on compute notes. Interactive jobs are processes in which you can interactively run programs on the computer, useful for debugging and/or coding. Batch jobs are non-interactive jobs that are run by the node and returned back to you. These can be parallelized, and will also run regardless of whether you are logged in or not. You can have at most 4 interactive sessions at once. Transfer nodes; used for transferring files, accessed via ssh transfer HPC has multiple \"partitions\", which are used for different purposes. There are also special use nodes. devel : default for interactive jobs day : default for batch jobs week : default for long jobs (>24 hours) gpu : nodes with GPU access bigmem : nodes for jobs with large RAM/memory requirements mpi : for highly-parallelized code pi_NAME : PI and lab specific nodes available for purchace from YCPC Cheat Sheet Interactive jobs: salloc to submit interactive job. Flags: -p or --partition= (default devel /interactive) -t or --time= (DD-HH:MM:SS or DD-HH time limit) --mem-per-cpu= (default 5gb per cpu) module load to load common software also module list to list available software module purge to remove all currently loaded software Example code: salloc -t 1:00:00 module load miniconda conda create -n env_name python=3.9 jupyter pandas conda activate env_name conda install pkg1 pkg2 module load miniconda conda activate env_name Batch jobs: sbatch to submit batch job. Flags: -j or --job-name= (job name) -o or --output= (output file name) --mail-user (email address to receive alerts about job completions, default: Yale address) --mail-type=ALL (receive email notifs at beginning and end of job) squeue --me (get status of all your submitted jobs) seff JOBID (get job stats when done e.g. CPU usage, time run) scancel JOBID (cancel job) htop -u NETID (view all current processes under your name) Misc commands: getquota (see remaining storage) dsq for large numbers of identical jobs Example code: #!/bin/bash #SBATCH -J example_job #SBATCH -p dat #SBATCH -t 12:00:00 #SBATCH --mail-type=ALL module purge module load miniconda conda activate my_env python my_python.py Example Use Case: Cloning Remote Repository At first, attempting to clone a repository in the standard way (e.g. git clone https://github.com/LevensteinLab/Lab-Handbook.git ) may not work. This is because GitHub doesn't know how to handle a request from a remote computer. You must first authenticate yourself. We can repeat the same process we used to authenticate ourselves for the cluster, but for GitHub, which offers the ability to add SSH keys. While logged into the cluster, again run ssh-keygen . Click enter to accept the default directory for where the keys will be stored. Choose a passphrase. You will need to remember this, as it provides access to your private key. Navigate to that directory and open the public key. This may look something like: cd /gpfs/radev/home/vv266/.ssh/ followed by cat id_ed25519.pub Copy that text and open your GitHub profile. Navigate to Settings > SSH and GPG keys > New SSH key . Then paste your public key into the box. Return to the HPC and type ssh -T git@github.com . After you type in your passphrase, you should see a message like Hi vviggyy! You've successfully authenticated, but GitHub does not provide shell access. You should now be able to clone repositories into the HPC environment. When you want to do so, visit the repository website, click the green <> Code button, and tap \"SSH\" (NOT the HTTPS button!) Use this URL when cloning e.g. git clone git@github.com:LevensteinLab/Lab-Handbook.git Set up a conda environment like above to run it! Reference: Introduction to HPC Clusters (YouTube Video) (1:16 hr workshop video going over SLURM and how to log-in) Getting Started page Documentation Page . Submit help requests or attend drop-in office hours (via Zoom) on Wednesdays at 11am-12pm Check out info on all clusters offered by the YCRC . They're named after famous academics. Any potential system outages can be checked here . Common SLURM commands for interacting with jobs and the scheduler YCRC HPC Policies ( make sure to read this before requesting an account )","title":"HPC"},{"location":"Resources/hpc/#getting-access-to-the-misha-hpc","text":"As part of computational research, we will need to dispatch jobs to high-performance computing (HPC) clusters. Access to these clusters gives us stronger power for computationally-intensive tasks like training models. Running the same process on your local machine may take much more time. To get started visit this page for some info about the HPC prepared by the Yale Center for Research Computing (YCRC) specifically for the Wu Tsai Institute. To use the cluster off-campus, you will need to use a VPN, please see the vpn.md file for instructions.","title":"Getting access to the Misha HPC"},{"location":"Resources/hpc/#instructions","text":"Fill out the form to access the cluster, noting Dan as the PI from which to get access. You should get access in ~48 hours. Receive email from hpc@yale.edu with your username and instructions on how to login. Choose login method. Access to Misha needs to be done through Secure Shell (SSH). Other clusters have a web interface for logging on (Bouchet, Grace, McCleary, and Milgram). Find the links for the platform, called Open OnDemand (OOD), here . ( First time login only ) Generate your public and private ssh keys. These keys are used to authenticate you during the remote login (i.e. they tell the cluster that you're you.). Keep the private key a secret! Instructions on how to do this can be found here . Note: the example in the documentation uses the RSA encryption scheme, but using the ssh-keygen command on Macs without any additional argument will use the Ed25519 encryption scheme. The key still works and will be stored in something like id_ed25519.pub . Sidebar from Viggy: If you're interested in math, I'd highly recommend reading up on RSA. The RSA public/private key method works beause it's easy to multiply two large prime numbers together, but extremely hard to factor that product back into those primes! ( First time login only ) Upload your public key to the SSH Key Uploader . This allows the cluster to associate it with your netID, which you use to sign in. Login to the cluster. Use the Terminal: Type ssh YOUR_NET_ID@misha.ycrc.yale.edu . It will prompt you for your passcode. After you provide it, it will ask you choose a second authentication option. Type 1 to authenticate via a DUO push notification. Use your IDE: Open VSCode, and click the blue button in the bottom left corner of the screen. It looks like two chevron arrows pointing to each other. Click SSH, and Add New SSH Host Type ssh YOUR_NET_ID@misha.ycrc.yale.edu If it asks you for a config file, select the one with the .ssh/ path (often the first option). This tells VSCode where to look for your private key (which is still protected by your passcode). Enter your passcode when prompted. Type 1 to send a DUO push notification, and accept it. Submit jobs! Type exit to close the connection.","title":"Instructions"},{"location":"Resources/hpc/#about-the-hpc","text":"Consists of multiple groups of computers called nodes . Login node is shared between all users; handles all user logins and is usually excluded from running actual code jobs Compute nodes which are the majority of all the computers in the HPC; where the tasks are performed Can run both interactive and batch jobs on compute notes. Interactive jobs are processes in which you can interactively run programs on the computer, useful for debugging and/or coding. Batch jobs are non-interactive jobs that are run by the node and returned back to you. These can be parallelized, and will also run regardless of whether you are logged in or not. You can have at most 4 interactive sessions at once. Transfer nodes; used for transferring files, accessed via ssh transfer HPC has multiple \"partitions\", which are used for different purposes. There are also special use nodes. devel : default for interactive jobs day : default for batch jobs week : default for long jobs (>24 hours) gpu : nodes with GPU access bigmem : nodes for jobs with large RAM/memory requirements mpi : for highly-parallelized code pi_NAME : PI and lab specific nodes available for purchace from YCPC","title":"About the HPC"},{"location":"Resources/hpc/#cheat-sheet","text":"Interactive jobs: salloc to submit interactive job. Flags: -p or --partition= (default devel /interactive) -t or --time= (DD-HH:MM:SS or DD-HH time limit) --mem-per-cpu= (default 5gb per cpu) module load to load common software also module list to list available software module purge to remove all currently loaded software Example code: salloc -t 1:00:00 module load miniconda conda create -n env_name python=3.9 jupyter pandas conda activate env_name conda install pkg1 pkg2 module load miniconda conda activate env_name Batch jobs: sbatch to submit batch job. Flags: -j or --job-name= (job name) -o or --output= (output file name) --mail-user (email address to receive alerts about job completions, default: Yale address) --mail-type=ALL (receive email notifs at beginning and end of job) squeue --me (get status of all your submitted jobs) seff JOBID (get job stats when done e.g. CPU usage, time run) scancel JOBID (cancel job) htop -u NETID (view all current processes under your name) Misc commands: getquota (see remaining storage) dsq for large numbers of identical jobs Example code: #!/bin/bash #SBATCH -J example_job #SBATCH -p dat #SBATCH -t 12:00:00 #SBATCH --mail-type=ALL module purge module load miniconda conda activate my_env python my_python.py","title":"Cheat Sheet"},{"location":"Resources/hpc/#example-use-case-cloning-remote-repository","text":"At first, attempting to clone a repository in the standard way (e.g. git clone https://github.com/LevensteinLab/Lab-Handbook.git ) may not work. This is because GitHub doesn't know how to handle a request from a remote computer. You must first authenticate yourself. We can repeat the same process we used to authenticate ourselves for the cluster, but for GitHub, which offers the ability to add SSH keys. While logged into the cluster, again run ssh-keygen . Click enter to accept the default directory for where the keys will be stored. Choose a passphrase. You will need to remember this, as it provides access to your private key. Navigate to that directory and open the public key. This may look something like: cd /gpfs/radev/home/vv266/.ssh/ followed by cat id_ed25519.pub Copy that text and open your GitHub profile. Navigate to Settings > SSH and GPG keys > New SSH key . Then paste your public key into the box. Return to the HPC and type ssh -T git@github.com . After you type in your passphrase, you should see a message like Hi vviggyy! You've successfully authenticated, but GitHub does not provide shell access. You should now be able to clone repositories into the HPC environment. When you want to do so, visit the repository website, click the green <> Code button, and tap \"SSH\" (NOT the HTTPS button!) Use this URL when cloning e.g. git clone git@github.com:LevensteinLab/Lab-Handbook.git Set up a conda environment like above to run it!","title":"Example Use Case: Cloning Remote Repository"},{"location":"Resources/hpc/#reference","text":"Introduction to HPC Clusters (YouTube Video) (1:16 hr workshop video going over SLURM and how to log-in) Getting Started page Documentation Page . Submit help requests or attend drop-in office hours (via Zoom) on Wednesdays at 11am-12pm Check out info on all clusters offered by the YCRC . They're named after famous academics. Any potential system outages can be checked here . Common SLURM commands for interacting with jobs and the scheduler YCRC HPC Policies ( make sure to read this before requesting an account )","title":"Reference:"},{"location":"Resources/mailing_lists/","text":"Mailing lists/groups at Yale Mailing lists/groups you may wish to sign up for/get added to, and how. Click the links to be redirected to submission forms. For most, you'll need to input your email, name, and the answer to a bot-prevention question. You may also choose an optional password to prevent anyone from messing with your subscription. *=Strongly recommended Mailing Lists Neuroscience mailing list Interdepartmental Neuroscience Program (INP) mailing list * Wu Tsai Institute (WTI) mailing list Research in Progress (RIP) mailing list - Ask Dan to email on your behalf * WTI NeuroAI Journal Club mailing list APplied PHilosophy In NEuroscience (APHINE) Quantitative Biology (QBio) talks Foundations of Data Science Institute talks - visit subscribe.yale.edu and find \"FDS Announcements\" under the \"Research Administration\" category It's also possible to check out all mailman@yale links or manage your subscriptions with the links below: All mailman.yale.edu mailing lists Manage subscriptions ( This doesn't seem to manage ALL subscriptions but it does show many ) Slack Workspaces WTI Slack - Ask Dan to add you Levenstein Lab Slack - Ask Dan to add you","title":"Mailing Lists"},{"location":"Resources/mailing_lists/#mailing-listsgroups-at-yale","text":"Mailing lists/groups you may wish to sign up for/get added to, and how. Click the links to be redirected to submission forms. For most, you'll need to input your email, name, and the answer to a bot-prevention question. You may also choose an optional password to prevent anyone from messing with your subscription. *=Strongly recommended","title":"Mailing lists/groups at Yale"},{"location":"Resources/mailing_lists/#mailing-lists","text":"Neuroscience mailing list Interdepartmental Neuroscience Program (INP) mailing list * Wu Tsai Institute (WTI) mailing list Research in Progress (RIP) mailing list - Ask Dan to email on your behalf * WTI NeuroAI Journal Club mailing list APplied PHilosophy In NEuroscience (APHINE) Quantitative Biology (QBio) talks Foundations of Data Science Institute talks - visit subscribe.yale.edu and find \"FDS Announcements\" under the \"Research Administration\" category It's also possible to check out all mailman@yale links or manage your subscriptions with the links below: All mailman.yale.edu mailing lists Manage subscriptions ( This doesn't seem to manage ALL subscriptions but it does show many )","title":"Mailing Lists"},{"location":"Resources/mailing_lists/#slack-workspaces","text":"WTI Slack - Ask Dan to add you Levenstein Lab Slack - Ask Dan to add you","title":"Slack Workspaces"},{"location":"Resources/mental_health/","text":"Mental health et al My hope is that you won\u2019t need to use these, but I think everyone should be aware that they exist, and how to access them, in case you or someone you know can be helped by them https://yalehealth.yale.edu/department/mental-health-counseling https://your.yale.edu/working-at-yale/benefits/your-well-being https://chaplain.yale.edu If you know of more, please add them","title":"Mental Health"},{"location":"Resources/mental_health/#mental-health-et-al","text":"My hope is that you won\u2019t need to use these, but I think everyone should be aware that they exist, and how to access them, in case you or someone you know can be helped by them https://yalehealth.yale.edu/department/mental-health-counseling https://your.yale.edu/working-at-yale/benefits/your-well-being https://chaplain.yale.edu If you know of more, please add them","title":"Mental health et al"},{"location":"Resources/printers/","text":"The driver for the printer can be found here: User Support Page ECOSYS PA4000cx Support Page And instructions on how to install it can be found here: Mac Driver Setup Guide Office Printer Information: Location : Stationary nook in front of 1126B, 11th Floor, 100 College St. Printer Model : ECOSYS PA4000cx Printer Name : YUCOLL100X01126AM1.MED.YALE.INTERNAL Printer Setup Tutorial (Step-by-step): Download the driver for the printer This can be done through the \"Web Installer\" option, which will download an installer that picks the right driver for you, or the \"Printer Driver\" option, which will download the driver itself. Ensure you are downloading the one that corresponds to the model above Connect to the printer through your device For Mac: This is Settings > Printers & Scanners > Add Printer, Scanner, or Fax Click the IP button (looks like a litle globe) Add the name of the printer ( YUCOLL100X01126AM1.MED.YALE.INTERNAL ) into the Address field, and a text line will show underneath saying Valid and complete host name or address . The Name , Location , and Use fields will all populate in the box below. You should see: Name: YUCOLL100X01126AM1.MED.YALE.INTERNAL Location: 100 COLLEGE RM 1126 Use: Kyocera ECOSYS PA4000cx KPDL Optionally: change Protocol to Line Printer Daemon - LPD format. This is recommended by the manual. Click the Add button. You should be able to print! NOTE: You must be connected to the YaleSecure network to use the printer over wireless. If you are not connected, the printer will fail. The printer is already connected to YaleSecure so you should not need to touch the WiFi settings.","title":"Printing"},{"location":"Resources/prnn_tutorial/","text":"Predictive RNNs There are some extra steps in managing the requirements needed for the Predictive RNN project. This guide should help you get everything set up on Misha. Ensure you have an account on Misha, and log on. Make sure to allocate an interactive session (e.g. salloc -t 2:00:00 )! Make sure you've also set up SSH cloning from the cluster, because you'll need to clone repositories into your storage. We're using SSH clone links from here out. See the page on HPCs for more information on this. Clone the pRNN repository into your project folder ( git clone git@github.com:LevensteinLab/pRNN.git ). In your HOME directory (accessible by typing cd ~ ): Make a folder for the virtual enviroment mkdir venvs . Clone Dan's fork of gym-minigrid ( git clone git@github.com:dlevenstein/gym-minigrid.git gym-minigrid-dan-fork ). Create a conda environment with Python 3.9. Misha doesn't come with Python 3.9 out of the box, and we need this version for later dependencies. Type module load miniconda to ensure conda is loaded for use. Run conda create -n base39 python=3.9 to make an environment called base39 with python 3.9 installed. Activate it ( conda activate base39 ). Make the PredictiveReplay environment. This is done by running make_venv.sh . First comment out/change the following lines. This will ensure that the correct environments remain active. module --force purge module load python/3.9 virtualenv $VENV_DIR changed to virtualenv -p ~/.conda/envs/base39/bin/python $VENV_DIR (this ensures we're making the virtualenv with python 3.9) Add pip install virtualenv before the line in step 3. #pip3 install gym-minigrid changed to pip3 install -e ../../gym-minigrid-dan-fork (this ensure we're using Dan's forked version) Run bash make_venv.sh to create the environment. Load the environment. This is done by loading load_venv.sh Comment out the following lines again. This will prevent the underlying conda environment from being purged. module --force purge module load python/3.9 Run bash load_venv.sh Activate the venv environment. Run source ~/venvs/PredictiveReplay_39/bin/activate . by now you should have two parenthesized environment names by each terminal prompt, like this (PredictiveReplay_39) (base39) [yourNetID@blahblah.misha]$ . Double check that gym-minigrid is installed correctly. Run pip list | grep minigrid . If nothing shows up, it didn't install correctly. Run cd ~/gym-minigrid-dan-fork , then pip3 install -e . to install it into the environment. In your terminal (with both environments activated), run: pip install \"pip<24.1\" pip install setuptools==59.5.0 wheel=0.37.0 pip3 install gym==0.21.0 --no-binary :all: Rerun bash make_venv.sh then bash load_venv.sh . Sidebar from Viggy: To be completely honest, I have no idea why steps 9 & 10 work. I spent many hours trying to fix a random numpy error that pops up in the tutorial.ipynb , but doing steps 9 and 10 fixes it, despite not reinstalling a different version of numpy. My hypothesis is that the downgraded version of pip , setuptools , and wheel help us install this version of gym , and when we rerun make_venv.sh , we can reinstall the correct version of numpy ( 1.22.4 instead of 1.26.x that it likes to do). It could be an issue with the order in which we install the packages at first. If you continue to have issues, try steps 9 and 10 again, and \"turning [your kernel] on and off again\". Or ask me, and we can figure it out. One day, I will figure out how to do this with fewer steps. Finally, make sure that the jupyter notebook kernel can recognize this environment. Run pip install ipykernel (this will install it inside both environments). Run ipython kernel install --user --name=prnn-kernel . To allow jupyter notebooks to pick it up. If you run jupyter kernelspec list , you should see prnn-kernel as an option. You may need to restart your VSCode or kernel here. You should be able to run tutorial.ipynb now. This contains a single run setting up some environments. You may get a SyntaxError . This is because there's a small typo to fix. If you go to line 62 in prnn > utils > Shell.py , you may see an extra ): . Delete that.","title":"pRNN Tutorial"},{"location":"Resources/prnn_tutorial/#predictive-rnns","text":"There are some extra steps in managing the requirements needed for the Predictive RNN project. This guide should help you get everything set up on Misha. Ensure you have an account on Misha, and log on. Make sure to allocate an interactive session (e.g. salloc -t 2:00:00 )! Make sure you've also set up SSH cloning from the cluster, because you'll need to clone repositories into your storage. We're using SSH clone links from here out. See the page on HPCs for more information on this. Clone the pRNN repository into your project folder ( git clone git@github.com:LevensteinLab/pRNN.git ). In your HOME directory (accessible by typing cd ~ ): Make a folder for the virtual enviroment mkdir venvs . Clone Dan's fork of gym-minigrid ( git clone git@github.com:dlevenstein/gym-minigrid.git gym-minigrid-dan-fork ). Create a conda environment with Python 3.9. Misha doesn't come with Python 3.9 out of the box, and we need this version for later dependencies. Type module load miniconda to ensure conda is loaded for use. Run conda create -n base39 python=3.9 to make an environment called base39 with python 3.9 installed. Activate it ( conda activate base39 ). Make the PredictiveReplay environment. This is done by running make_venv.sh . First comment out/change the following lines. This will ensure that the correct environments remain active. module --force purge module load python/3.9 virtualenv $VENV_DIR changed to virtualenv -p ~/.conda/envs/base39/bin/python $VENV_DIR (this ensures we're making the virtualenv with python 3.9) Add pip install virtualenv before the line in step 3. #pip3 install gym-minigrid changed to pip3 install -e ../../gym-minigrid-dan-fork (this ensure we're using Dan's forked version) Run bash make_venv.sh to create the environment. Load the environment. This is done by loading load_venv.sh Comment out the following lines again. This will prevent the underlying conda environment from being purged. module --force purge module load python/3.9 Run bash load_venv.sh Activate the venv environment. Run source ~/venvs/PredictiveReplay_39/bin/activate . by now you should have two parenthesized environment names by each terminal prompt, like this (PredictiveReplay_39) (base39) [yourNetID@blahblah.misha]$ . Double check that gym-minigrid is installed correctly. Run pip list | grep minigrid . If nothing shows up, it didn't install correctly. Run cd ~/gym-minigrid-dan-fork , then pip3 install -e . to install it into the environment. In your terminal (with both environments activated), run: pip install \"pip<24.1\" pip install setuptools==59.5.0 wheel=0.37.0 pip3 install gym==0.21.0 --no-binary :all: Rerun bash make_venv.sh then bash load_venv.sh . Sidebar from Viggy: To be completely honest, I have no idea why steps 9 & 10 work. I spent many hours trying to fix a random numpy error that pops up in the tutorial.ipynb , but doing steps 9 and 10 fixes it, despite not reinstalling a different version of numpy. My hypothesis is that the downgraded version of pip , setuptools , and wheel help us install this version of gym , and when we rerun make_venv.sh , we can reinstall the correct version of numpy ( 1.22.4 instead of 1.26.x that it likes to do). It could be an issue with the order in which we install the packages at first. If you continue to have issues, try steps 9 and 10 again, and \"turning [your kernel] on and off again\". Or ask me, and we can figure it out. One day, I will figure out how to do this with fewer steps. Finally, make sure that the jupyter notebook kernel can recognize this environment. Run pip install ipykernel (this will install it inside both environments). Run ipython kernel install --user --name=prnn-kernel . To allow jupyter notebooks to pick it up. If you run jupyter kernelspec list , you should see prnn-kernel as an option. You may need to restart your VSCode or kernel here. You should be able to run tutorial.ipynb now. This contains a single run setting up some environments. You may get a SyntaxError . This is because there's a small typo to fix. If you go to line 62 in prnn > utils > Shell.py , you may see an extra ): . Delete that.","title":"Predictive RNNs"},{"location":"Resources/recommended_reading/","text":"Recommended Reading Some recommended foundational papers and reviews to get acquainted with selected topics of interest to the lab Sleep https://pubmed.ncbi.nlm.nih.gov/23589831/ https://journals.physiology.org/doi/abs/10.1152/physrev.00054.2024 https://www.nature.com/articles/nrn2762 https://www.cell.com/neuron/fulltext/S0896-6273(23)00201-5 https://www.sciencedirect.com/science/article/pii/S0896627304005409 Memory consolidation https://pubmed.ncbi.nlm.nih.gov/7624455/ https://www.nature.com/articles/nrn2762 https://pubmed.ncbi.nlm.nih.gov/21764357/ https://www.cell.com/neuron/fulltext/S0896-6273(23)00201-5 https://www.sciencedirect.com/science/article/pii/S0896627304005409 Artificial Neural Networks (ANNs) https://www.sciencedirect.com/science/article/pii/S0896627320307054 neuroAI https://www.nature.com/articles/s41583-023-00705-w https://www.nature.com/articles/s41593-019-0520-2 Replay in brains and ANNs https://www.cell.com/trends/neurosciences/abstract/S0166-2236(21)00144-2 https://direct.mit.edu/neco/article-abstract/33/11/2908/107071/Replay-in-Deep-Learning-Current-Approaches-and hippocampus https://pmc.ncbi.nlm.nih.gov/articles/PMC4648295/ Hippocampus/MEC - recent models The hippocampus as a predictive map , Stachenfeld KL et al, 2017, Nat Neurosci Vector-based navigation using grid-like representations in artificial agents , Banino A et al, 2018, Nature The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation , Whittington JCR et al, 2020, Cell A model of egocentric to allocentric understanding in mammalian brains , Uria B et al, 2020, bioRxiv Place cells may simply be memory cells: Memory compression leads to spatial tuning and history dependence , Benna MK et al, 2021, Proc Natl Acad Sci U S A Predictive learning as a network mechanism for extracting low-dimensional latent space representations , Recanatesi S et al, 2021, Nat Commun Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps , George D et al, 2021, Nat Commun A unified theory for the computational and mechanistic origins of grid cells , Sorscher B et al, 2023, Neuron Self-Supervised Learning of Representations for Space Generates Multi-Modular Grid Cells , Schaeffer R et al, 2023, NeurIPS Episodic and associative memory from spatial scaffolds in the hippocampus , Chandra S et al, 2025, Nature General - scientific process https://web.stanford.edu/~fukamit/schwartz-2008.pdf https://www.nature.com/articles/s41587-023-02074-2 modeling and theory https://pubmed.ncbi.nlm.nih.gov/39257366/ https://www.jstor.org/stable/184253","title":"Recommended Reading"},{"location":"Resources/recommended_reading/#recommended-reading","text":"Some recommended foundational papers and reviews to get acquainted with selected topics of interest to the lab Sleep https://pubmed.ncbi.nlm.nih.gov/23589831/ https://journals.physiology.org/doi/abs/10.1152/physrev.00054.2024 https://www.nature.com/articles/nrn2762 https://www.cell.com/neuron/fulltext/S0896-6273(23)00201-5 https://www.sciencedirect.com/science/article/pii/S0896627304005409 Memory consolidation https://pubmed.ncbi.nlm.nih.gov/7624455/ https://www.nature.com/articles/nrn2762 https://pubmed.ncbi.nlm.nih.gov/21764357/ https://www.cell.com/neuron/fulltext/S0896-6273(23)00201-5 https://www.sciencedirect.com/science/article/pii/S0896627304005409 Artificial Neural Networks (ANNs) https://www.sciencedirect.com/science/article/pii/S0896627320307054 neuroAI https://www.nature.com/articles/s41583-023-00705-w https://www.nature.com/articles/s41593-019-0520-2 Replay in brains and ANNs https://www.cell.com/trends/neurosciences/abstract/S0166-2236(21)00144-2 https://direct.mit.edu/neco/article-abstract/33/11/2908/107071/Replay-in-Deep-Learning-Current-Approaches-and hippocampus https://pmc.ncbi.nlm.nih.gov/articles/PMC4648295/ Hippocampus/MEC - recent models The hippocampus as a predictive map , Stachenfeld KL et al, 2017, Nat Neurosci Vector-based navigation using grid-like representations in artificial agents , Banino A et al, 2018, Nature The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation , Whittington JCR et al, 2020, Cell A model of egocentric to allocentric understanding in mammalian brains , Uria B et al, 2020, bioRxiv Place cells may simply be memory cells: Memory compression leads to spatial tuning and history dependence , Benna MK et al, 2021, Proc Natl Acad Sci U S A Predictive learning as a network mechanism for extracting low-dimensional latent space representations , Recanatesi S et al, 2021, Nat Commun Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps , George D et al, 2021, Nat Commun A unified theory for the computational and mechanistic origins of grid cells , Sorscher B et al, 2023, Neuron Self-Supervised Learning of Representations for Space Generates Multi-Modular Grid Cells , Schaeffer R et al, 2023, NeurIPS Episodic and associative memory from spatial scaffolds in the hippocampus , Chandra S et al, 2025, Nature General - scientific process https://web.stanford.edu/~fukamit/schwartz-2008.pdf https://www.nature.com/articles/s41587-023-02074-2 modeling and theory https://pubmed.ncbi.nlm.nih.gov/39257366/ https://www.jstor.org/stable/184253","title":"Recommended Reading"},{"location":"Resources/science_general/","text":"The term \"research\" is a broad way to describe many different skills. Designing scientifically-sound experiments, testing your hypotheses, and analyzing data are only part of the equation. Research is also about asking the right questions, choosing which problems to work on, and knowing when to move on. Here are a few highly-recommended reads on how to do good research and what types of expectations are reasonable for yourself. How to develop good research questions (Nature Human Behavior, Megan A. K. Peters) - Article outlining the \"phases\" of how to come up with a good direction and common pitfalls to avoid. How to choose a good scientific problem You and Your Research (Dr. Richard Hamming, retired Bell Labs scientist) - Transcript of a talk given to scientists at the prolific Bell Labs, on the question \"Why do so few scientists make significant contributions and so many are forgotten in the long run?\". How to make your research career impactful How a Ph.D. is like riding a bike (Science blog, Ehsan Hamzehpoor) - Article on expectations during a Ph.D. and what the purpose of one is. Advice for Applying to PhD Programs - Anita Devineni's blog post on applying to grad school How to Apply for Postdoctoral Positions and Choose the Right One - Anita's blog post on choosing a postdoc The Genius Fallacy The illustrated guide to a Ph.D. Tough love: an insensitive guide to thriving in your PhD You're only human: a six-step strategy to surviving your PhD Add more yourself...!","title":"Doing Science"},{"location":"Resources/travel/","text":"To book travel and accommodation for conferences, use World Travel/Concur, Yale's platform for business travel. See here for more information. You can log into the Concur website here . There is a training in Workday called \"Booking Federally Sponsored Travel with World Travel\" that you should complete in order to understand the restrictions on booking travel when using federal funds. You have a few options when it comes to airports: Bradley International Airport (BDL) in Hartford, CT: drive/Uber Newark International Airport (EWR) in Newark, NJ: direct Amtrak train from New Haven John F. Kennedy Airport (JFK) in Queens, NYC: Amtrak to LIRR or E train to AirTrain LaGuardia Airport (LGA) in Queens, NYC: Metro-North to Harlem-125th Street, then Uber or M60+ bus The three NYC airports (including EWR) are generally far cheaper and better connected. The direct Amtrak train from New Haven to Newark/EWR makes that the most convenient option. You can book Amtrak tickets in Concur (you should book them in advance) or use the TrainTime App to buy Metro-North/LIRR tickets (less important to buy in advance). To navigate the MTA (NYC's public transit system) use Google Maps or e.g. CityMapper for real-time arrival info. The MTA has tap-to-pay terminals, so you can purchase a ticket on-site using your card or phone.","title":"Travel"},{"location":"Resources/vpn/","text":"Some of Yale's internal tools, such as the cluster, are only available on the Yale network. If you are off campus, you will need to use a VPN. For Windows and Mac OS X, download the Cisco AnyConnect VPN Client from the ITS Software Library . See this guide for Linux and for the full instructions, which will be briefly outlined below. Once you have installed the Cisco software, type in the server address: access.yale.edu and click connect. This should open an authentication tab in your browser, where you will be able to log in using your Yale net ID and password.","title":"VPN"},{"location":"Resources/vs_code/","text":"To get started with VS Code try a tutorial, such as this one . The program itself will also give you some tips. Some basic tips to get started: 1. Link VS Code with your GitHub account 2. Open a repository, such as Lab-Handbook 3. Try out the terminal (e.g. try echo $SHELL to see which shell your computer runs by default) 4. Install the Python extension 5. Create an environment 6. Use the debugger. You can copy Resources/debug_me.py to try it out! If you want, you can create a new project repo that you will also use for the pytorch tutorial as part of your first project.","title":"VS Code"}]}